{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python (project1)",
   "name": "project1"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 80874,
     "databundleVersionId": 8794587,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30733,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# Import necessary libraries for data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import mathematical constant for potential circular calculations\n",
    "from math import pi\n",
    "\n",
    "# Import plotting library for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import preprocessing tools from scikit-learn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Import tools for splitting data and model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Import LightGBM for gradient boosting framework\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Import XGBoost for another gradient boosting framework\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Import CatBoost for a different gradient boosting algorithm\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Import ensemble methods from scikit-learn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# Import linear and logistic regression models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import boosting and decision tree algorithms\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Import tools for hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Suppress all warnings to keep output clean\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T05:45:31.458288Z",
     "start_time": "2024-08-23T05:45:31.447724Z"
    }
   },
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T05:45:31.608884Z",
     "start_time": "2024-08-23T05:45:31.599137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import make_scorer, mean_absolute_percentage_error\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "mape_scorer = make_scorer(mean_absolute_percentage_error, greater_is_better=False)"
   ],
   "outputs": [],
   "execution_count": 193
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the training dataset from the specified Kaggle input path\n",
    "base_train_df = pd.read_csv('train.csv')\n",
    "# Display the first 5 rows of the training dataset for a quick overview\n",
    "base_train_df.head(5)"
   ],
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T05:45:31.807785Z",
     "start_time": "2024-08-23T05:45:31.773229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  warehouse        date  orders holiday_name  holiday  shutdown  \\\n",
       "0  Prague_1  2020-12-05  6895.0          NaN        0         0   \n",
       "1  Prague_1  2020-12-06  6584.0          NaN        0         0   \n",
       "2  Prague_1  2020-12-07  7030.0          NaN        0         0   \n",
       "3  Prague_1  2020-12-08  6550.0          NaN        0         0   \n",
       "4  Prague_1  2020-12-09  6910.0          NaN        0         0   \n",
       "\n",
       "   mini_shutdown  shops_closed  winter_school_holidays  school_holidays  \\\n",
       "0              0             0                       0                0   \n",
       "1              0             0                       0                0   \n",
       "2              0             0                       0                0   \n",
       "3              0             0                       0                0   \n",
       "4              0             0                       0                0   \n",
       "\n",
       "   blackout  mov_change  frankfurt_shutdown  precipitation  snow  \\\n",
       "0         0         0.0                   0            0.0   0.0   \n",
       "1         0         0.0                   0            0.0   0.0   \n",
       "2         0         0.0                   0            0.0   0.0   \n",
       "3         0         0.0                   0            0.8   0.0   \n",
       "4         0         0.0                   0            0.5   0.0   \n",
       "\n",
       "   user_activity_1  user_activity_2                   id  \n",
       "0           1722.0          32575.0  Prague_1_2020-12-05  \n",
       "1           1688.0          32507.0  Prague_1_2020-12-06  \n",
       "2           1696.0          32552.0  Prague_1_2020-12-07  \n",
       "3           1681.0          32423.0  Prague_1_2020-12-08  \n",
       "4           1704.0          32410.0  Prague_1_2020-12-09  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warehouse</th>\n",
       "      <th>date</th>\n",
       "      <th>orders</th>\n",
       "      <th>holiday_name</th>\n",
       "      <th>holiday</th>\n",
       "      <th>shutdown</th>\n",
       "      <th>mini_shutdown</th>\n",
       "      <th>shops_closed</th>\n",
       "      <th>winter_school_holidays</th>\n",
       "      <th>school_holidays</th>\n",
       "      <th>blackout</th>\n",
       "      <th>mov_change</th>\n",
       "      <th>frankfurt_shutdown</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>snow</th>\n",
       "      <th>user_activity_1</th>\n",
       "      <th>user_activity_2</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prague_1</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>6895.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1722.0</td>\n",
       "      <td>32575.0</td>\n",
       "      <td>Prague_1_2020-12-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prague_1</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>6584.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1688.0</td>\n",
       "      <td>32507.0</td>\n",
       "      <td>Prague_1_2020-12-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prague_1</td>\n",
       "      <td>2020-12-07</td>\n",
       "      <td>7030.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>32552.0</td>\n",
       "      <td>Prague_1_2020-12-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prague_1</td>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>6550.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1681.0</td>\n",
       "      <td>32423.0</td>\n",
       "      <td>Prague_1_2020-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prague_1</td>\n",
       "      <td>2020-12-09</td>\n",
       "      <td>6910.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1704.0</td>\n",
       "      <td>32410.0</td>\n",
       "      <td>Prague_1_2020-12-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 194
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the test dataset from the specified Kaggle input path\n",
    "base_test_df = pd.read_csv('test.csv')\n",
    "# Display the first 5 rows of the test dataset for a quick overview\n",
    "base_test_df.head(5)"
   ],
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T05:45:32.136484Z",
     "start_time": "2024-08-23T05:45:32.124194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  warehouse        date holiday_name  holiday  shops_closed  \\\n",
       "0  Prague_1  2024-03-16          NaN        0             0   \n",
       "1  Prague_1  2024-03-17          NaN        0             0   \n",
       "2  Prague_1  2024-03-18          NaN        0             0   \n",
       "3  Prague_1  2024-03-19          NaN        0             0   \n",
       "4  Prague_1  2024-03-20          NaN        0             0   \n",
       "\n",
       "   winter_school_holidays  school_holidays                   id  \n",
       "0                       0                0  Prague_1_2024-03-16  \n",
       "1                       0                0  Prague_1_2024-03-17  \n",
       "2                       0                0  Prague_1_2024-03-18  \n",
       "3                       0                0  Prague_1_2024-03-19  \n",
       "4                       0                0  Prague_1_2024-03-20  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warehouse</th>\n",
       "      <th>date</th>\n",
       "      <th>holiday_name</th>\n",
       "      <th>holiday</th>\n",
       "      <th>shops_closed</th>\n",
       "      <th>winter_school_holidays</th>\n",
       "      <th>school_holidays</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prague_1</td>\n",
       "      <td>2024-03-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Prague_1_2024-03-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prague_1</td>\n",
       "      <td>2024-03-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Prague_1_2024-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prague_1</td>\n",
       "      <td>2024-03-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Prague_1_2024-03-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prague_1</td>\n",
       "      <td>2024-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Prague_1_2024-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prague_1</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Prague_1_2024-03-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 195
  },
  {
   "cell_type": "code",
   "source": "# Define base features by excluding the 'id' column from the test dataset\nbase_features = base_test_df.drop(columns=['id']).columns\n# Extract the 'id' column from the test dataset for later use in predictions\ntest_id = base_test_df['id']",
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T05:45:32.216346Z",
     "start_time": "2024-08-23T05:45:32.212739Z"
    }
   },
   "outputs": [],
   "execution_count": 196
  },
  {
   "cell_type": "code",
   "source": "# Concatenate base features with the 'orders' column from the training dataset\n# This creates a new dataframe with only the features and target variable for training\ntrain_df = pd.concat([base_train_df[base_features], base_train_df['orders']], axis=1)\n\n# Prepare the test dataset by selecting only the base features\ntest_df = base_test_df[base_features]",
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T05:45:32.460055Z",
     "start_time": "2024-08-23T05:45:32.455011Z"
    }
   },
   "outputs": [],
   "execution_count": 197
  },
  {
   "cell_type": "markdown",
   "source": "> ## `Preprocessing`",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Display information about the structure of the training and test datasets\nprint(train_df.info())\nprint('='*60)\nprint(test_df.info())",
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T05:45:32.718201Z",
     "start_time": "2024-08-23T05:45:32.710601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7340 entries, 0 to 7339\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   warehouse               7340 non-null   object \n",
      " 1   date                    7340 non-null   object \n",
      " 2   holiday_name            218 non-null    object \n",
      " 3   holiday                 7340 non-null   int64  \n",
      " 4   shops_closed            7340 non-null   int64  \n",
      " 5   winter_school_holidays  7340 non-null   int64  \n",
      " 6   school_holidays         7340 non-null   int64  \n",
      " 7   orders                  7340 non-null   float64\n",
      "dtypes: float64(1), int64(4), object(3)\n",
      "memory usage: 458.9+ KB\n",
      "None\n",
      "============================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 397 entries, 0 to 396\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   warehouse               397 non-null    object\n",
      " 1   date                    397 non-null    object\n",
      " 2   holiday_name            17 non-null     object\n",
      " 3   holiday                 397 non-null    int64 \n",
      " 4   shops_closed            397 non-null    int64 \n",
      " 5   winter_school_holidays  397 non-null    int64 \n",
      " 6   school_holidays         397 non-null    int64 \n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 21.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 198
  },
  {
   "cell_type": "code",
   "source": "# Combine training and test datasets for feature engineering\nall_df = pd.concat([train_df, test_df], sort=False).reset_index(drop=True)",
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T05:45:32.811724Z",
     "start_time": "2024-08-23T05:45:32.806870Z"
    }
   },
   "outputs": [],
   "execution_count": 199
  },
  {
   "cell_type": "code",
   "source": "# Convert 'date' column to datetime for easier manipulation\ndate_start = pd.to_datetime(all_df['date'], errors='coerce').min()\n\n# Extract various time-based features from the 'date' column\ndate_col = ['date']\nfor _col in date_col:\n    date_col = pd.to_datetime(all_df[_col], errors='coerce')\n    # Extract year, month, day, etc., from the date\n    all_df[_col + \"_year\"] = date_col.dt.year.fillna(-1)\n    all_df[_col + \"_month\"] = date_col.dt.month.fillna(-1)\n    all_df[_col + \"_day\"] = date_col.dt.day.fillna(-1)\n    all_df[_col + \"_day_of_week\"] = date_col.dt.dayofweek.fillna(-1)\n    all_df[_col + \"_week_of_year\"] = date_col.dt.isocalendar().week.fillna(-1)\n\n    # Calculate number of days since the start date\n    all_df[_col + \"_num\"] = (date_col-date_start).dt.days.fillna(-1)\n    \n    # Adjust day of year for leap years\n    all_df[_col + \"_day_of_year\"] = date_col.dt.dayofyear.fillna(-1)\n    all_df[_col + \"_day_of_year\"] = np.where( (all_df[_col + \"_year\"]%4==0)&(all_df[_col + \"_month\"]>2), \n                                              all_df[_col + \"_day_of_year\"]-1, \n                                              all_df[_col + \"_day_of_year\"])\n\n    # Extract quarter information\n    all_df[_col + \"_quarter\"] = date_col.dt.quarter.fillna(-1)\n    \n    # Create boolean features for start and end of various time periods\n    all_df[_col + \"_is_month_start\"] = date_col.dt.is_month_start.astype(int).fillna(-1)\n    all_df[_col + \"_is_month_end\"] = date_col.dt.is_month_end.astype(int).fillna(-1)\n    all_df[_col + \"_is_quarter_start\"] = date_col.dt.is_quarter_start.astype(int).fillna(-1)\n    all_df[_col + \"_is_quarter_end\"] = date_col.dt.is_quarter_end.astype(int).fillna(-1)\n\n# Reconvert 'date' column to datetime type for consistency\nall_df['date'] = pd.to_datetime(all_df['date'])\n\n# Display the resulting dataframe with all engineered features\nall_df",
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T05:45:33.024789Z",
     "start_time": "2024-08-23T05:45:33.002271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       warehouse       date holiday_name  holiday  shops_closed  \\\n",
       "0       Prague_1 2020-12-05          NaN        0             0   \n",
       "1       Prague_1 2020-12-06          NaN        0             0   \n",
       "2       Prague_1 2020-12-07          NaN        0             0   \n",
       "3       Prague_1 2020-12-08          NaN        0             0   \n",
       "4       Prague_1 2020-12-09          NaN        0             0   \n",
       "...          ...        ...          ...      ...           ...   \n",
       "7732  Budapest_1 2024-05-11          NaN        0             0   \n",
       "7733  Budapest_1 2024-05-12          NaN        0             0   \n",
       "7734  Budapest_1 2024-05-13          NaN        0             0   \n",
       "7735  Budapest_1 2024-05-14          NaN        0             0   \n",
       "7736  Budapest_1 2024-05-15          NaN        0             0   \n",
       "\n",
       "      winter_school_holidays  school_holidays  orders  date_year  date_month  \\\n",
       "0                          0                0  6895.0       2020          12   \n",
       "1                          0                0  6584.0       2020          12   \n",
       "2                          0                0  7030.0       2020          12   \n",
       "3                          0                0  6550.0       2020          12   \n",
       "4                          0                0  6910.0       2020          12   \n",
       "...                      ...              ...     ...        ...         ...   \n",
       "7732                       0                0     NaN       2024           5   \n",
       "7733                       0                0     NaN       2024           5   \n",
       "7734                       0                0     NaN       2024           5   \n",
       "7735                       0                0     NaN       2024           5   \n",
       "7736                       0                0     NaN       2024           5   \n",
       "\n",
       "      date_day  date_day_of_week  date_week_of_year  date_num  \\\n",
       "0            5                 5                 49         0   \n",
       "1            6                 6                 49         1   \n",
       "2            7                 0                 50         2   \n",
       "3            8                 1                 50         3   \n",
       "4            9                 2                 50         4   \n",
       "...        ...               ...                ...       ...   \n",
       "7732        11                 5                 19      1253   \n",
       "7733        12                 6                 19      1254   \n",
       "7734        13                 0                 20      1255   \n",
       "7735        14                 1                 20      1256   \n",
       "7736        15                 2                 20      1257   \n",
       "\n",
       "      date_day_of_year  date_quarter  date_is_month_start  date_is_month_end  \\\n",
       "0                  339             4                    0                  0   \n",
       "1                  340             4                    0                  0   \n",
       "2                  341             4                    0                  0   \n",
       "3                  342             4                    0                  0   \n",
       "4                  343             4                    0                  0   \n",
       "...                ...           ...                  ...                ...   \n",
       "7732               131             2                    0                  0   \n",
       "7733               132             2                    0                  0   \n",
       "7734               133             2                    0                  0   \n",
       "7735               134             2                    0                  0   \n",
       "7736               135             2                    0                  0   \n",
       "\n",
       "      date_is_quarter_start  date_is_quarter_end  \n",
       "0                         0                    0  \n",
       "1                         0                    0  \n",
       "2                         0                    0  \n",
       "3                         0                    0  \n",
       "4                         0                    0  \n",
       "...                     ...                  ...  \n",
       "7732                      0                    0  \n",
       "7733                      0                    0  \n",
       "7734                      0                    0  \n",
       "7735                      0                    0  \n",
       "7736                      0                    0  \n",
       "\n",
       "[7737 rows x 20 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warehouse</th>\n",
       "      <th>date</th>\n",
       "      <th>holiday_name</th>\n",
       "      <th>holiday</th>\n",
       "      <th>shops_closed</th>\n",
       "      <th>winter_school_holidays</th>\n",
       "      <th>school_holidays</th>\n",
       "      <th>orders</th>\n",
       "      <th>date_year</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_day</th>\n",
       "      <th>date_day_of_week</th>\n",
       "      <th>date_week_of_year</th>\n",
       "      <th>date_num</th>\n",
       "      <th>date_day_of_year</th>\n",
       "      <th>date_quarter</th>\n",
       "      <th>date_is_month_start</th>\n",
       "      <th>date_is_month_end</th>\n",
       "      <th>date_is_quarter_start</th>\n",
       "      <th>date_is_quarter_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prague_1</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6895.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prague_1</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6584.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>340</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prague_1</td>\n",
       "      <td>2020-12-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7030.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>341</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prague_1</td>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6550.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>342</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prague_1</td>\n",
       "      <td>2020-12-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6910.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>343</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7732</th>\n",
       "      <td>Budapest_1</td>\n",
       "      <td>2024-05-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>1253</td>\n",
       "      <td>131</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7733</th>\n",
       "      <td>Budapest_1</td>\n",
       "      <td>2024-05-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1254</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7734</th>\n",
       "      <td>Budapest_1</td>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1255</td>\n",
       "      <td>133</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7735</th>\n",
       "      <td>Budapest_1</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1256</td>\n",
       "      <td>134</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7736</th>\n",
       "      <td>Budapest_1</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1257</td>\n",
       "      <td>135</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7737 rows Ã— 20 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 200
  },
  {
   "cell_type": "code",
   "source": [
    "# Apply sine and cosine transformations to capture cyclical patterns in time\n",
    "\n",
    "# Commented out: Yearly sine and cosine transformations based on the year itself\n",
    "# Import the math library for pi\n",
    "from math import pi\n",
    "\n",
    "all_df['month_sin'] = all_df['date_month'] * np.sin(2 * pi * all_df['date_month'])\n",
    "all_df['month_cos'] = all_df['date_month'] * np.cos(2 * pi * all_df['date_month'])\n",
    "all_df['day_sin'] = all_df['date_day'] * np.sin(2 * pi * all_df['date_day'])\n",
    "all_df['day_cos'] = all_df['date_day'] * np.cos(2 * pi * all_df['date_day'])\n",
    "\n",
    "all_df['year_sin'] = np.sin(2 * pi * all_df[\"date_day_of_year\"])\n",
    "all_df['year_cos'] = np.cos(2 * pi * all_df['date_day_of_year'])\n"
   ],
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T05:45:33.067537Z",
     "start_time": "2024-08-23T05:45:33.059762Z"
    }
   },
   "outputs": [],
   "execution_count": 201
  },
  {
   "cell_type": "code",
   "source": "# Handle missing values in the 'holiday_name' column by replacing them with 'None'\nall_df['holiday_name'].fillna('None', inplace=True)",
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T05:45:33.103134Z",
     "start_time": "2024-08-23T05:45:33.099440Z"
    }
   },
   "outputs": [],
   "execution_count": 202
  },
  {
   "cell_type": "code",
   "source": [
    "# Perform One-Hot Encoding on the 'holiday_name' column\n",
    "enc = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit and transform the 'holiday_name' column into a new encoded dataframe\n",
    "holiday_encoded = enc.fit_transform(all_df[['holiday_name']])\n",
    "# Create a dataframe from the encoded data with appropriate column names\n",
    "encoded_df = pd.DataFrame(holiday_encoded, columns=enc.get_feature_names_out(['holiday_name']))\n",
    "# Concatenate the original dataframe with the encoded holiday features\n",
    "all_df = pd.concat([all_df, encoded_df], axis=1)"
   ],
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T05:45:33.382175Z",
     "start_time": "2024-08-23T05:45:33.369544Z"
    }
   },
   "outputs": [],
   "execution_count": 203
  },
  {
   "cell_type": "code",
   "source": "# Remove the original 'holiday_name' column after encoding\nall_df = all_df.drop('holiday_name', axis=1)\n\n# Apply Label Encoding to the 'warehouse' column\nle = preprocessing.LabelEncoder()\n# Transform categorical 'warehouse' data into numerical labels\nall_df['warehouse'] = le.fit_transform(all_df['warehouse'])\n\n# Commented out: Label Encoding for 'holiday_name' (not used due to One-Hot Encoding)\n# all_df['holiday_name'] = le.fit_transform(all_df['holiday_name'])",
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T05:45:33.391002Z",
     "start_time": "2024-08-23T05:45:33.385179Z"
    }
   },
   "outputs": [],
   "execution_count": 204
  },
  {
   "cell_type": "code",
   "source": [
    "# Feature engineering for holidays: create features for the day before and after holidays\n",
    "all_df['holiday_before'] = all_df['holiday'].shift(1).fillna(0).astype(int)\n",
    "all_df['holiday_after'] = all_df['holiday'].shift(-1).fillna(0).astype(int)"
   ],
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T05:45:33.659501Z",
     "start_time": "2024-08-23T05:45:33.649135Z"
    }
   },
   "outputs": [],
   "execution_count": 205
  },
  {
   "cell_type": "code",
   "source": "# Split the data back into training and test sets based on the presence of 'orders'\ntrain_df_le = all_df[~all_df['orders'].isnull()]\ntest_df_le = all_df[all_df['orders'].isnull()]\n\n# Remove the 'date' column from both datasets as it's no longer needed for modeling\ntrain_df_le = train_df_le.drop(columns=['date'], axis=1)\ntest_df_le = test_df_le.drop(columns=['date'], axis=1)",
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T05:45:33.971746Z",
     "start_time": "2024-08-23T05:45:33.961912Z"
    }
   },
   "outputs": [],
   "execution_count": 206
  },
  {
   "cell_type": "markdown",
   "source": "> ## `Modeling (Ensemble + Stacking)`",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "**Ensemble**\n* LightGBM \n* XGBoost \n* RandomForest \n* CatBoost\n* Logistic Regression\n* Ada Boost\n* Decision Tree\n* Gradient Boost",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Data Splitting\n",
    "# Set a random seed for reproducibility\n",
    "random_seed = 777 \n",
    "\n",
    "# Prepare features and target variable\n",
    "X = train_df_le.drop(columns=['orders'])\n",
    "y = train_df_le['orders']\n",
    "\n",
    "# buggy part\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1, random_state=random_seed)"
   ],
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T05:45:41.714953Z",
     "start_time": "2024-08-23T05:45:41.697411Z"
    }
   },
   "outputs": [],
   "execution_count": 207
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T00:37:35.665019Z",
     "start_time": "2024-08-22T22:52:30.579901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define search spaces for Bayesian Optimization\n",
    "search_spaces = {\n",
    "    'lgb': {\n",
    "        'n_estimators': Integer(100, 1000),\n",
    "        'num_leaves': Integer(20, 100),\n",
    "        'learning_rate': Real(0.001, 0.1, prior='log-uniform'),\n",
    "        'colsample_bytree': Real(0.4, 1.0),\n",
    "        'subsample': Real(0.5, 1.0),\n",
    "        'min_child_weight': Integer(1, 10),\n",
    "        'lambda_l1': Real(0, 1),\n",
    "        'lambda_l2': Real(0, 1)\n",
    "    },\n",
    "    'xgb': {\n",
    "        'n_estimators': Integer(100, 1000),\n",
    "        'max_depth': Integer(3, 15),\n",
    "        'learning_rate': Real(0.001, 0.1, prior='log-uniform'),\n",
    "        'colsample_bytree': Real(0.4, 1.0),\n",
    "        'subsample': Real(0.5, 1.0),\n",
    "        'min_child_weight': Integer(1, 10),\n",
    "        'gamma': Real(0, 5),\n",
    "        'lambda': Real(0, 1),\n",
    "        'alpha': Real(0, 1)\n",
    "    },\n",
    "    'cat': {\n",
    "        'iterations': Integer(100, 1000),\n",
    "        'depth': Integer(4, 12),\n",
    "        'learning_rate': Real(0.001, 0.1, prior='log-uniform'),\n",
    "        'l2_leaf_reg': Real(1, 10),\n",
    "        'border_count': Integer(32, 255),\n",
    "        'bagging_temperature': Real(0.0, 1.0),\n",
    "        'random_strength': Real(0.0, 1.0)\n",
    "    },\n",
    "    'rf': {\n",
    "        'n_estimators': Integer(100, 1000),\n",
    "        'max_depth': Integer(5, 50),\n",
    "        'min_samples_split': Integer(2, 20),\n",
    "        'min_samples_leaf': Integer(1, 10),\n",
    "        'max_features': Real(0.1, 1.0)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize the models with default parameters and GPU/multicore settings\n",
    "models = {\n",
    "    'lgb': LGBMRegressor(device='gpu',random_state=random_seed),\n",
    "    'xgb': XGBRegressor(tree_method='gpu_hist', random_state=random_seed),\n",
    "    'cat': CatBoostRegressor(task_type='GPU', random_state=random_seed, verbose=0),\n",
    "    'rf': RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=random_seed)\n",
    "}\n",
    "\n",
    "\n",
    "# models which won't be tuned\n",
    "lr_model = LogisticRegression(random_state=random_seed)\n",
    "ad_model = AdaBoostRegressor(random_state=random_seed)\n",
    "dt_model = DecisionTreeRegressor(random_state=random_seed)\n",
    "gb_model = GradientBoostingRegressor(random_state=random_seed)\n",
    "\n",
    "\n",
    "lr_model.fit(X_train, y_train)\n",
    "ad_model.fit(X_train, y_train)\n",
    "dt_model.fit(X_train, y_train)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Bayesian Optimization for each model\n",
    "opt_models = {}\n",
    "for model_name, model in models.items():\n",
    "    opt = BayesSearchCV(estimator=model, search_spaces=search_spaces.get(model_name, {}), n_iter=30, cv=5, random_state=random_seed,verbose=1,scoring=mape_scorer)\n",
    "    opt.fit(X_train, y_train)\n",
    "    opt_models[model_name] = opt.best_estimator_\n",
    "    print(model_name, opt.best_score_, opt.best_params_)\n",
    "\n",
    "# untuned model; doing this for time saving\n",
    "opt_models['lr'] =lr_model\n",
    "opt_models['ad'] =ad_model\n",
    "opt_models['dt'] =dt_model\n",
    "opt_models['gb'] =gb_model\n",
    "\n",
    "# Train optimized models on full training data\n",
    "stacking_train = np.zeros((X_train.shape[0], len(opt_models)))\n",
    "\n",
    "for i, (model_name, model) in enumerate(opt_models.items()):\n",
    "    stacking_train[:, i] = model.predict(X_train)\n",
    "\n",
    "\n",
    "# Define search spaces for the meta-models\n",
    "meta_search_spaces = {\n",
    "    'meta_model_1': {  # LGBMRegressor\n",
    "        'n_estimators': Integer(100, 1000),\n",
    "        'num_leaves': Integer(20, 100),\n",
    "        'learning_rate': Real(0.001, 0.1, prior='log-uniform'),\n",
    "        'colsample_bytree': Real(0.4, 1.0),\n",
    "    },\n",
    "    'meta_model_2': {  # CatBoostRegressor\n",
    "        'iterations': Integer(100, 1000),\n",
    "        'depth': Integer(4, 12),\n",
    "        'learning_rate': Real(0.001, 0.1, prior='log-uniform')\n",
    "    },\n",
    "    'meta_model_3': {  # XGBRegressor\n",
    "        'n_estimators': Integer(100, 1000),\n",
    "        'max_depth': Integer(3, 15),\n",
    "        'learning_rate': Real(0.001, 0.1, prior='log-uniform'),\n",
    "        'colsample_bytree': Real(0.4, 1.0),\n",
    "        'subsample': Real(0.5, 1.0)\n",
    "    },\n",
    "    'meta_model_4': {  # RandomForestRegressor\n",
    "        'n_estimators': Integer(100, 1000),\n",
    "        'max_depth': Integer(5, 50),\n",
    "        'min_samples_split': Integer(2, 20),\n",
    "        'min_samples_leaf': Integer(1, 10),\n",
    "        'max_features': Real(0.1, 1.0)\n",
    "    },\n",
    "    'meta_model_5': {  # GradientBoostingRegressor\n",
    "        'n_estimators': Integer(100, 1000),\n",
    "        'max_depth': Integer(3, 15),\n",
    "        'learning_rate': Real(0.001, 0.1, prior='log-uniform'),\n",
    "        'subsample': Real(0.5, 1.0),\n",
    "        'min_samples_split': Integer(2, 20),\n",
    "        'min_samples_leaf': Integer(1, 10),\n",
    "        'max_features': Real(0.1, 1.0)\n",
    "    },\n",
    "    'meta_model_6': {  # DecisionTreeRegressor\n",
    "        'max_depth': Integer(3, 15),\n",
    "        'min_samples_split': Integer(2, 20),\n",
    "        'min_samples_leaf': Integer(1, 10),\n",
    "        'max_features': Categorical(['sqrt', 'log2']),\n",
    "        'ccp_alpha': Real(0.0, 0.1)  # Cost-complexity pruning parameter\n",
    "    },\n",
    "    'meta_model_7': {  # AdaBoostRegressor\n",
    "        'n_estimators': Integer(50, 500),\n",
    "        'learning_rate': Real(0.001, 1.0, prior='log-uniform'),\n",
    "        'loss': Categorical(['linear', 'square', 'exponential'])\n",
    "    },\n",
    "    'meta_model_8': {  # LinearRegression\n",
    "        'fit_intercept': Categorical([True, False])\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize and optimize meta-models using Bayesian Optimization\n",
    "meta_models = {\n",
    "    'meta_model_1': LGBMRegressor(device='gpu', random_state=random_seed),\n",
    "    'meta_model_2': CatBoostRegressor(task_type='GPU', random_state=random_seed, verbose=0),\n",
    "    'meta_model_3': XGBRegressor(tree_method='gpu_hist', random_state=random_seed),\n",
    "    'meta_model_4': RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=random_seed),\n",
    "    'meta_model_5': GradientBoostingRegressor(random_state=random_seed),\n",
    "    'meta_model_6': DecisionTreeRegressor(random_state=random_seed),\n",
    "    'meta_model_7': AdaBoostRegressor(random_state=random_seed),\n",
    "    'meta_model_8': LinearRegression(n_jobs=-1)\n",
    "}\n",
    "\n",
    "opt_meta_models = {}\n",
    "for model_name, model in meta_models.items():\n",
    "    opt_meta = BayesSearchCV(estimator=model, search_spaces=meta_search_spaces.get(model_name, {}), n_iter=10, cv=5, random_state=random_seed, verbose=1, scoring=mape_scorer)\n",
    "    opt_meta.fit(stacking_train, y_train)\n",
    "    opt_meta_models[model_name] = opt_meta.best_estimator_\n",
    "    print(model_name, opt_meta.best_score_, opt_meta.best_params_)\n",
    "\n",
    "# drop the order column \n",
    "test_df_le=test_df_le.drop(columns=['orders'])\n",
    "\n",
    "level_2_train = np.zeros((X_train.shape[0], len(opt_meta_models)))\n",
    "for i, (model_name, model) in enumerate(opt_meta_models.items()):\n",
    "    print(model_name)\n",
    "    level_2_train[:, i] = model.predict(stacking_train)\n",
    "\n",
    "# the model first pass through original layer\n",
    "stacking_t=np.zeros((test_df_le.shape[0], len(opt_models)))\n",
    "for i, (model_name, model) in enumerate(opt_models.items()):\n",
    "    stacking_t[:, i] = model.predict(test_df_le)\n",
    "# pass the second layer. Which is meta-layer\n",
    "meta_stack=np.zeros((test_df_le.shape[0], len(opt_meta_models)))\n",
    "for i, (model_name, model) in enumerate(opt_meta_models.items()):\n",
    "    meta_stack[:, i] = model.predict(stacking_t)\n",
    "\n",
    "\n",
    "initial_weights = np.ones(len(meta_models)) / len(meta_models)\n",
    "\n",
    "# Final prediction\n",
    "submit_pred = np.dot(meta_stack, initial_weights)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001371 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001270 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001298 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001091 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001218 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001219 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.004441 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001061 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001206 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001266 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.003131 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001256 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001178 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001366 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001118 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001091 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001221 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001249 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001008 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.000950 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001183 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001175 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001242 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001188 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001258 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001237 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001013 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001209 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001236 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001170 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001264 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001252 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001322 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001143 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001193 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001204 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001179 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001165 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001247 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001172 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001245 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001246 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001277 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001209 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001103 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001148 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001304 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001180 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001276 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001173 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4814005397267494, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4814005397267494\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4814005397267494, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4814005397267494\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001221 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4814005397267494, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4814005397267494\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4814005397267494, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4814005397267494\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4814005397267494, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4814005397267494\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001290 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4814005397267494, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4814005397267494\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4814005397267494, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4814005397267494\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4814005397267494, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4814005397267494\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001419 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4814005397267494, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4814005397267494\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4814005397267494, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4814005397267494\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4814005397267494, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4814005397267494\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001285 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4814005397267494, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4814005397267494\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4814005397267494, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4814005397267494\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4814005397267494, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4814005397267494\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001049 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4814005397267494, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4814005397267494\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7500957323539137, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7500957323539137\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7500957323539137, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7500957323539137\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001351 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7500957323539137, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7500957323539137\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7500957323539137, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7500957323539137\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7500957323539137, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7500957323539137\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001265 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7500957323539137, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7500957323539137\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7500957323539137, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7500957323539137\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7500957323539137, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7500957323539137\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001135 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7500957323539137, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7500957323539137\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7500957323539137, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7500957323539137\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7500957323539137, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7500957323539137\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001011 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7500957323539137, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7500957323539137\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7500957323539137, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7500957323539137\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7500957323539137, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7500957323539137\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001227 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7500957323539137, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7500957323539137\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.29844187170257425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.29844187170257425\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3173025460289528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3173025460289528\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.29844187170257425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.29844187170257425\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3173025460289528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3173025460289528\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001586 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.29844187170257425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.29844187170257425\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3173025460289528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3173025460289528\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.29844187170257425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.29844187170257425\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3173025460289528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3173025460289528\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.29844187170257425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.29844187170257425\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3173025460289528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3173025460289528\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001205 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.29844187170257425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.29844187170257425\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3173025460289528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3173025460289528\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.29844187170257425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.29844187170257425\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3173025460289528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3173025460289528\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.29844187170257425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.29844187170257425\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3173025460289528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3173025460289528\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001249 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.29844187170257425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.29844187170257425\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3173025460289528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3173025460289528\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.29844187170257425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.29844187170257425\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3173025460289528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3173025460289528\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.29844187170257425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.29844187170257425\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3173025460289528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3173025460289528\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001305 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.29844187170257425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.29844187170257425\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3173025460289528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3173025460289528\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.29844187170257425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.29844187170257425\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3173025460289528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3173025460289528\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.29844187170257425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.29844187170257425\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3173025460289528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3173025460289528\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001112 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.29844187170257425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.29844187170257425\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3173025460289528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3173025460289528\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001190 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001175 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001292 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001122 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001218 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001100 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.006551 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001312 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001089 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001130 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.578498692101556, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.578498692101556\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6338689504509191, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6338689504509191\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.578498692101556, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.578498692101556\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6338689504509191, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6338689504509191\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001352 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.578498692101556, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.578498692101556\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6338689504509191, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6338689504509191\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.578498692101556, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.578498692101556\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6338689504509191, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6338689504509191\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.578498692101556, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.578498692101556\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6338689504509191, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6338689504509191\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001147 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.578498692101556, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.578498692101556\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6338689504509191, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6338689504509191\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.578498692101556, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.578498692101556\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6338689504509191, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6338689504509191\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.578498692101556, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.578498692101556\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6338689504509191, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6338689504509191\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001170 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.578498692101556, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.578498692101556\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6338689504509191, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6338689504509191\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.578498692101556, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.578498692101556\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6338689504509191, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6338689504509191\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.578498692101556, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.578498692101556\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6338689504509191, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6338689504509191\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001319 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.578498692101556, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.578498692101556\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6338689504509191, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6338689504509191\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.578498692101556, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.578498692101556\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6338689504509191, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6338689504509191\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.578498692101556, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.578498692101556\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6338689504509191, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6338689504509191\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001392 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.578498692101556, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.578498692101556\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6338689504509191, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6338689504509191\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9912494525897914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9912494525897914\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9912494525897914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9912494525897914\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001247 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9912494525897914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9912494525897914\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9912494525897914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9912494525897914\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9912494525897914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9912494525897914\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001241 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9912494525897914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9912494525897914\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9912494525897914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9912494525897914\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9912494525897914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9912494525897914\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001334 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9912494525897914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9912494525897914\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9912494525897914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9912494525897914\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9912494525897914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9912494525897914\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001133 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9912494525897914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9912494525897914\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9912494525897914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9912494525897914\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9912494525897914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9912494525897914\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001249 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9912494525897914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9912494525897914\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001288 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001099 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001316 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001168 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001141 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07244536910264673, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07244536910264673\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07244536910264673, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07244536910264673\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001248 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07244536910264673, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07244536910264673\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07244536910264673, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07244536910264673\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07244536910264673, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07244536910264673\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001354 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07244536910264673, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07244536910264673\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07244536910264673, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07244536910264673\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07244536910264673, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07244536910264673\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001248 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07244536910264673, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07244536910264673\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07244536910264673, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07244536910264673\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07244536910264673, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07244536910264673\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001175 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07244536910264673, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07244536910264673\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07244536910264673, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07244536910264673\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07244536910264673, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07244536910264673\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001155 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07244536910264673, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07244536910264673\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6266552373357985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6266552373357985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6266552373357985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6266552373357985\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001529 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6266552373357985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6266552373357985\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6266552373357985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6266552373357985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6266552373357985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6266552373357985\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001193 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6266552373357985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6266552373357985\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6266552373357985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6266552373357985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6266552373357985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6266552373357985\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001137 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6266552373357985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6266552373357985\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6266552373357985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6266552373357985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6266552373357985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6266552373357985\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001171 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6266552373357985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6266552373357985\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6266552373357985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6266552373357985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6266552373357985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6266552373357985\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001292 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6266552373357985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6266552373357985\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2292619251211614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2292619251211614\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2292619251211614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2292619251211614\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001385 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2292619251211614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2292619251211614\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2292619251211614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2292619251211614\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2292619251211614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2292619251211614\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001198 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2292619251211614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2292619251211614\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2292619251211614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2292619251211614\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2292619251211614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2292619251211614\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001067 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2292619251211614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2292619251211614\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2292619251211614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2292619251211614\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2292619251211614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2292619251211614\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001180 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2292619251211614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2292619251211614\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2292619251211614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2292619251211614\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2292619251211614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2292619251211614\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001163 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2292619251211614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2292619251211614\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001416 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001126 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001197 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001155 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001300 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41177878873827223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41177878873827223\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41177878873827223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41177878873827223\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001367 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41177878873827223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41177878873827223\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41177878873827223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41177878873827223\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41177878873827223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41177878873827223\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001445 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41177878873827223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41177878873827223\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41177878873827223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41177878873827223\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41177878873827223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41177878873827223\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001254 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41177878873827223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41177878873827223\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41177878873827223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41177878873827223\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41177878873827223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41177878873827223\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001037 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41177878873827223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41177878873827223\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41177878873827223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41177878873827223\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41177878873827223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41177878873827223\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001161 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41177878873827223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41177878873827223\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001153 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001201 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001260 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001252 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.002153 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001174 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001182 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001057 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001179 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001155 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001533 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001185 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001206 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001172 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001397 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001454 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001235 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001270 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001107 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.005628 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001475 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001120 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001117 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001208 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001169 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8525392634178253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8525392634178253\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8525392634178253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8525392634178253\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001117 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8525392634178253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8525392634178253\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8525392634178253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8525392634178253\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8525392634178253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8525392634178253\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001313 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8525392634178253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8525392634178253\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8525392634178253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8525392634178253\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8525392634178253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8525392634178253\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001292 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8525392634178253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8525392634178253\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8525392634178253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8525392634178253\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8525392634178253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8525392634178253\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001317 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8525392634178253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8525392634178253\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8525392634178253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8525392634178253\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8525392634178253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8525392634178253\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.004813 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8525392634178253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8525392634178253\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.27063532749151525, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27063532749151525\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6416565355348314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6416565355348314\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.27063532749151525, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27063532749151525\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6416565355348314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6416565355348314\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 25\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001196 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.27063532749151525, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27063532749151525\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6416565355348314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6416565355348314\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.27063532749151525, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27063532749151525\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6416565355348314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6416565355348314\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.27063532749151525, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27063532749151525\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6416565355348314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6416565355348314\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001267 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.27063532749151525, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27063532749151525\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6416565355348314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6416565355348314\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.27063532749151525, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27063532749151525\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6416565355348314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6416565355348314\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.27063532749151525, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27063532749151525\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6416565355348314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6416565355348314\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 981\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001266 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.27063532749151525, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27063532749151525\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6416565355348314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6416565355348314\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.27063532749151525, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27063532749151525\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6416565355348314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6416565355348314\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.27063532749151525, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27063532749151525\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6416565355348314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6416565355348314\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001211 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.27063532749151525, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27063532749151525\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6416565355348314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6416565355348314\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.27063532749151525, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27063532749151525\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6416565355348314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6416565355348314\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.27063532749151525, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27063532749151525\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6416565355348314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6416565355348314\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.09 MB) transferred to GPU in 0.001230 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.27063532749151525, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27063532749151525\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6416565355348314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6416565355348314\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 987\n",
      "[LightGBM] [Info] Number of data points in the train set: 7339, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.11 MB) transferred to GPU in 0.001319 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5535.446110\n",
      "lgb -0.03431525589978293 OrderedDict({'colsample_bytree': 0.9090704690562509, 'lambda_l1': 0.5123226527180421, 'lambda_l2': 0.17762444404308067, 'learning_rate': 0.04939196011309037, 'min_child_weight': 8, 'n_estimators': 501, 'num_leaves': 53, 'subsample': 0.5052004980567765})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "xgb -0.03479350335656892 OrderedDict({'alpha': 0.0, 'colsample_bytree': 1.0, 'gamma': 5.0, 'lambda': 0.8926060892693777, 'learning_rate': 0.025678181688152554, 'max_depth': 15, 'min_child_weight': 10, 'n_estimators': 686, 'subsample': 0.5})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "cat -0.03654134204508268 OrderedDict({'bagging_temperature': 1.0, 'border_count': 133, 'depth': 12, 'iterations': 1000, 'l2_leaf_reg': 10.0, 'learning_rate': 0.1, 'random_strength': 0.0})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "rf -0.04140554064466247 OrderedDict({'max_depth': 31, 'max_features': 1.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000})\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000766 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000833 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1686\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000846 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1688\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.005956 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000762 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000655 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000851 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1686\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000757 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1688\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000887 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.001110 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000718 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000665 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1686\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000686 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1688\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000806 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000833 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000802 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000787 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1686\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000752 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1688\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000838 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000766 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000884 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000769 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1686\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000737 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1688\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000677 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000853 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000788 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000806 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1686\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000857 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1688\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000720 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000819 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000833 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000878 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1686\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000741 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1688\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000744 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000733 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000764 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000828 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1686\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000779 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1688\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000780 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000979 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000760 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000901 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1686\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000754 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1688\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000842 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000782 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000778 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000706 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1686\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000701 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1688\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000822 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.04 MB) transferred to GPU in 0.000884 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1693\n",
      "[LightGBM] [Info] Number of data points in the train set: 7339, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 8 dense feature groups (0.06 MB) transferred to GPU in 0.000974 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5535.446110\n",
      "meta_model_1 -0.0031662537231575303 OrderedDict({'colsample_bytree': 0.8037902863531624, 'learning_rate': 0.06678618920982962, 'n_estimators': 221, 'num_leaves': 69})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "meta_model_2 -0.013234504131189134 OrderedDict({'depth': 6, 'iterations': 547, 'learning_rate': 0.0595573883918703})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "meta_model_3 -0.0030628158674815315 OrderedDict({'colsample_bytree': 0.9090704690562509, 'learning_rate': 0.010583889705671753, 'max_depth': 5, 'n_estimators': 862, 'subsample': 0.8774801253694525})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "meta_model_4 -0.0008523846462005598 OrderedDict({'max_depth': 33, 'max_features': 0.8865827204872763, 'min_samples_leaf': 2, 'min_samples_split': 12, 'n_estimators': 533})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "meta_model_5 -0.0014620738068791285 OrderedDict({'learning_rate': 0.02138940088929268, 'max_depth': 10, 'max_features': 0.6713262756889268, 'min_samples_leaf': 4, 'min_samples_split': 14, 'n_estimators': 749, 'subsample': 0.6094913668371814})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "meta_model_6 -0.007753468632383104 OrderedDict({'ccp_alpha': 0.06650993101418151, 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 14})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "meta_model_7 -0.02662080955461319 OrderedDict({'learning_rate': 0.3510365561653655, 'loss': 'square', 'n_estimators': 130})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "meta_model_8 -1.9017318463897017e-16 OrderedDict({'fit_intercept': True})\n",
      "meta_model_1\n",
      "meta_model_2\n",
      "meta_model_3\n",
      "meta_model_4\n",
      "meta_model_5\n",
      "meta_model_6\n",
      "meta_model_7\n",
      "meta_model_8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n"
     ]
    }
   ],
   "execution_count": 164
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'colsample_bytree': 0.9090704690562509, 'lambda_l1': 0.5123226527180421, 'lambda_l2': 0.17762444404308067, 'learning_rate': 0.04939196011309037, 'min_child_weight': 8, 'n_estimators': 501, 'num_leaves': 53, 'subsample': 0.5052004980567765}\n",
    "alpha': 0.0, 'colsample_bytree': 1.0, 'gamma': 5.0, 'lambda': 0.8926060892693777, 'learning_rate': 0.025678181688152554, 'max_depth': 15, 'min_child_weight': 10, 'n_estimators': 686, 'subsample': 0.5\n",
    "bagging_temperature': 1.0, 'border_count': 133, 'depth': 12, 'iterations': 1000, 'l2_leaf_reg': 10.0, 'learning_rate': 0.1, 'random_strength': 0.0\n",
    "max_depth': 31, 'max_features': 1.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "> ## `Submit`",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a DataFrame for submission with 'id' and 'Target'\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_id,         # Test IDs for each prediction\n",
    "    'Target': submit_pred  # Final predictions for submission\n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission.to_csv('submission_ultimate1.csv', index=False)  # Save without including row indices\n",
    "\n",
    "# Print the submission DataFrame to verify the results\n",
    "print(submission)"
   ],
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T00:37:35.681402Z",
     "start_time": "2024-08-23T00:37:35.665019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        id        Target\n",
      "0      Prague_1_2024-03-16  10354.786501\n",
      "1      Prague_1_2024-03-17  10283.978299\n",
      "2      Prague_1_2024-03-18  10004.316190\n",
      "3      Prague_1_2024-03-19   9983.068800\n",
      "4      Prague_1_2024-03-20   9983.252076\n",
      "..                     ...           ...\n",
      "392  Budapest_1_2024-05-11   7123.248690\n",
      "393  Budapest_1_2024-05-12   6724.833991\n",
      "394  Budapest_1_2024-05-13   7992.263321\n",
      "395  Budapest_1_2024-05-14   7997.529854\n",
      "396  Budapest_1_2024-05-15   7996.436605\n",
      "\n",
      "[397 rows x 2 columns]\n"
     ]
    }
   ],
   "execution_count": 165
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###  Different data preprocessing\n",
    "Let's use different data scheme but same model"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T05:11:35.179215Z",
     "start_time": "2024-08-23T05:11:34.917447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the datasets\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Base features\n",
    "base_features = test_df.drop(columns=['id']).columns\n",
    "test_id = test_df['id']\n",
    "\n",
    "# Concatenate train and test datasets\n",
    "train_df = pd.concat([train_df[base_features], train_df['orders']], axis=1)\n",
    "\n",
    "test_df=test_df[base_features]\n",
    "\n",
    "train_test_df = pd.concat([train_df, test_df], sort=False).reset_index(drop=True)\n",
    "\n",
    "date_col = 'date'\n",
    "\n",
    "\n",
    "def base_features_processing(df):\n",
    "\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "\n",
    "    df[\"year\"] = df[date_col].dt.year.fillna(-1)\n",
    "    df[\"month\"] = df[date_col].dt.month.fillna(-1)\n",
    "    df[\"day\"] = df[date_col].dt.day.fillna(-1)\n",
    "    df[\"day_of_week\"] = df[date_col].dt.dayofweek.fillna(-1)\n",
    "\n",
    "    df[\"week_of_year\"] = df[date_col].dt.isocalendar().week.fillna(-1)\n",
    "\n",
    "\n",
    "    df[\"quarter\"] = df[date_col].dt.quarter.fillna(-1)\n",
    "    df[\"is_month_start\"] = df[date_col].dt.is_month_start.astype(int).fillna(-1)\n",
    "    df[\"is_month_end\"] = df[date_col].dt.is_month_end.astype(int).fillna(-1)\n",
    "    df[\"is_quarter_start\"] = df[date_col].dt.is_quarter_start.astype(int).fillna(-1)\n",
    "    df[\"is_quarter_end\"] = df[date_col].dt.is_quarter_end.astype(int).fillna(-1)\n",
    "\n",
    "\n",
    "    # check if the holiday is close.\n",
    "    df['holiday_before'] = df['holiday'].shift(1).fillna(0).astype(int)\n",
    "    df['holiday_after'] = df['holiday'].shift(-1).fillna(0).astype(int)\n",
    "\n",
    "    # total number of holidays in the corresponding month of that row\n",
    "    df['total_holidays_month'] = df.groupby(['year', 'month'])['holiday'].transform('sum')\n",
    "    # the total number of days that shops were closed in the corresponding week of that row\n",
    "    df['total_shops_closed_week'] = df.groupby(['year', 'week_of_year'])['shops_closed'].transform('sum')\n",
    "\n",
    "    df.drop(date_col, axis=1, inplace=True)\n",
    "\n",
    "    # Replace null values in holiday_name with 'None'\n",
    "    df['holiday_name'].fillna('None', inplace=True)\n",
    "\n",
    "    # OneHotEncoding for holiday_name\n",
    "\n",
    "    enc = OneHotEncoder(sparse_output=False)\n",
    "    holiday_encoded = enc.fit_transform(df[['holiday_name']])\n",
    "\n",
    "    encoded_df = pd.DataFrame(holiday_encoded, columns=enc.get_feature_names_out(['holiday_name']))\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "    df.drop('holiday_name', axis=1, inplace=True)\n",
    "\n",
    "    # LabelEncoding for warehouse column;\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    df['warehouse'] = le.fit_transform(df['warehouse'])\n",
    "\n",
    "    return df\n",
    "train_test_df=base_features_processing(train_test_df)\n",
    "# Apply sine and cosine transformations\n",
    "# The reason we do this is that we want all cyclical patterns captured\n",
    "# capture seasonality\n",
    "def add_fourier_terms(df, year_k, week_k, day_k):\n",
    "    for k in range(1, year_k+1):\n",
    "        df['year_sin_'+str(k)] = df['year'] * np.sin(2 * pi * df['year'])\n",
    "        df['year_cos_'+str(k)] = df['year'] * np.cos(2 * pi * df['year'])\n",
    "    for k in range(1, week_k+1):\n",
    "        df['month_sin_'+str(k)] = df['month'] * np.sin(2 * pi * df['month'])\n",
    "        df['month_cos_'+str(k)] = df['month'] * np.cos(2 * pi * df['month'])\n",
    "    for k in range(1, day_k+1):\n",
    "        df['day_sin_'+str(k)] = df['day'] * np.sin(2 * pi * df['day'])\n",
    "        df['day_cos_'+str(k)] = df['day'] * np.cos(2 * pi * df['day'])\n",
    "    for k in range(1, day_k+1):\n",
    "        df['quarter'+str(k)] = df['quarter'] * np.sin(2 * pi * df['quarter'])\n",
    "        df['quarter'+str(k)] = df['quarter'] * np.cos(2 * pi * df['quarter'])\n",
    "\n",
    "add_fourier_terms(train_test_df, year_k= 5, week_k=5, day_k=5)\n",
    "groupby_columns=['warehouse', 'holiday', 'shops_closed']\n",
    "print('groupby_columns: ', groupby_columns)\n",
    "\n",
    "train_test_df_2=train_test_df.copy()\n",
    "\n",
    "# Convert the data back to train_df and test_df\n",
    "train_df_processed = train_test_df_2[~train_test_df_2['orders'].isnull()]\n",
    "\n",
    "#train_df_processed.dropna(inplace=True)\n",
    "\n",
    "test_df_processed = train_test_df_2[train_test_df_2['orders'].isnull()]\n",
    "\n",
    "\n",
    "test_df_processed = test_df_processed.drop(columns=['orders'])\n",
    "\n",
    "test_data_len=len(test_df_processed)\n",
    "# Fill Na to make sure\n",
    "train_df_processed=train_df_processed.fillna(train_df_processed.mean())\n",
    "test_df_processed=test_df_processed.fillna(test_df_processed.mean())\n",
    "# Move target to the last column\n",
    "column_to_move = train_df_processed['orders']\n",
    "train_df_processed = train_df_processed.drop('orders', axis=1)\n",
    "train_df_processed = pd.concat([train_df_processed, column_to_move], axis=1)\n",
    "train_df_processed['orders_holiday'] = train_df_processed['orders'] * train_df_processed['holiday']\n",
    "train_df_processed['orders_wsh'] = train_df_processed['orders'] * train_df_processed['winter_school_holidays']\n",
    "\n",
    "train_df_processed['orders_sh'] = train_df_processed['orders'] * train_df_processed['school_holidays']\n",
    "\n",
    "train_df_processed['orders_shops_closed'] = train_df_processed['orders'] * train_df_processed['shops_closed']\n",
    "\n",
    "#train_df_processed['daily_avg']  = train_df_processed.groupby(['warehouse','day_of_week'])['orders'].transform('mean')\n",
    "#train_df_processed['monthly_avg'] = train_df_processed.groupby(['warehouse','month'])['orders'].transform('mean')\n",
    "\n",
    "train_df_processed['cumulative_orders'] = train_df_processed.groupby(groupby_columns)['orders'].cumsum()\n",
    "holiday_names=['holiday_name_1848 Revolution Memorial Day (Extra holiday)', 'holiday_name_2nd Christmas Day', \"holiday_name_All Saints' Day Holiday\", 'holiday_name_Christmas Eve', 'holiday_name_Cyrila a Metodej', 'holiday_name_Day of National Unity', 'holiday_name_Den boje za svobodu a demokracii', 'holiday_name_Den ceske statnosti', 'holiday_name_Den osvobozeni', 'holiday_name_Den vzniku samostatneho ceskoslovenskeho statu', 'holiday_name_Easter Monday', 'holiday_name_Good Friday', 'holiday_name_Independent Hungary Day', 'holiday_name_International womens day', 'holiday_name_Jan Hus', 'holiday_name_Labour Day', 'holiday_name_Memorial Day for the Martyrs of Arad', 'holiday_name_Memorial Day for the Victims of the Communist Dictatorships', 'holiday_name_Memorial Day for the Victims of the Holocaust', 'holiday_name_Memorial Day of the Republic', 'holiday_name_National Defense Day', 'holiday_name_New Years Day', 'holiday_name_None', 'holiday_name_Peace Festival in Augsburg', 'holiday_name_Reformation Day']\n",
    "train_df_processed=train_df_processed.fillna(train_df_processed.mean())\n",
    "train_df_processed.dropna(inplace=True)\n",
    "train_df_processed.sort_values(by=['year','month','day'])\n",
    "# frequncy at which each warehouse appears in our test dataset\n",
    "warehouse_counts = test_df_processed['warehouse'].value_counts().reset_index()\n",
    "warehouse_counts.columns = ['warehouse', 'count']\n",
    "#val=warehouse_counts['warehouse'][0]\n",
    "\n",
    "wr_count = warehouse_counts['count'][warehouse_counts['warehouse'] == 0].item()\n",
    "print(wr_count)\n",
    "# Extract the records for extra features for each warehouse and insert into test_df_processed\n",
    "def get_latest_matching_record(train_df, test_df, feature):\n",
    "    # Create a copy of the test dataframe\n",
    "    result_df = test_df.copy()\n",
    "    # Process each warehouse separately\n",
    "    for warehouse in test_df['warehouse'].unique():\n",
    "        # Extract the records for the current warehouse\n",
    "        wr_count = warehouse_counts['count'][warehouse_counts['warehouse'] == warehouse].item()\n",
    "        #print(f'wharehouse {warehouse} occurances in test df: ', wr_count)\n",
    "        last_values = train_df[train_df['warehouse'] == warehouse].tail(wr_count)[feature].values\n",
    "        # Get the rows corresponding to the current warehouse in the result dataframe\n",
    "        warehouse_rows = result_df[result_df['warehouse'] == warehouse].index\n",
    "        # Assign the last wr_count values to the corresponding rows in the result dataframe\n",
    "        for i in range(wr_count):          #(min(wr_count, len(warehouse_rows))):\n",
    "            result_df.loc[warehouse_rows[i], feature] = last_values[i]\n",
    "\n",
    "    return result_df\n",
    "test_df_processed= get_latest_matching_record(train_df_processed, test_df_processed,  'orders_holiday')\n",
    "test_df_processed= get_latest_matching_record(train_df_processed, test_df_processed,  'orders_wsh')\n",
    "\n",
    "test_df_processed= get_latest_matching_record(train_df_processed, test_df_processed,  'orders_sh')\n",
    "test_df_processed= get_latest_matching_record(train_df_processed, test_df_processed,  'orders_shops_closed')\n",
    "#test_df_processed= get_latest_matching_record(train_df_processed, test_df_processed, 'daily_avg')\n",
    "#test_df_processed= get_latest_matching_record(train_df_processed, test_df_processed, 'monthly_avg')\n",
    "test_df_processed= get_latest_matching_record(train_df_processed, test_df_processed, 'cumulative_orders')\n",
    "test_df_processed=test_df_processed.fillna(test_df_processed.mean())\n",
    "X = train_df_processed.drop(columns=['orders'])\n",
    "y = train_df_processed['orders']\n",
    "# Show the first few rows of the updated dataset\n",
    "print('train_df_processed.head()', train_df_processed.head())\n",
    "print('test_df_processed.head()', test_df_processed.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groupby_columns:  ['warehouse', 'holiday', 'shops_closed']\n",
      "61\n",
      "train_df_processed.head()    warehouse  holiday  shops_closed  winter_school_holidays  school_holidays  \\\n",
      "0          4        0             0                       0                0   \n",
      "1          4        0             0                       0                0   \n",
      "2          4        0             0                       0                0   \n",
      "3          4        0             0                       0                0   \n",
      "4          4        0             0                       0                0   \n",
      "\n",
      "   year  month  day  day_of_week  week_of_year  ...  quarter2  quarter3  \\\n",
      "0  2020     12    5            5            49  ...       4.0       4.0   \n",
      "1  2020     12    6            6            49  ...       4.0       4.0   \n",
      "2  2020     12    7            0            50  ...       4.0       4.0   \n",
      "3  2020     12    8            1            50  ...       4.0       4.0   \n",
      "4  2020     12    9            2            50  ...       4.0       4.0   \n",
      "\n",
      "   quarter4  quarter5  orders  orders_holiday  orders_wsh  orders_sh  \\\n",
      "0       4.0       4.0  6895.0             0.0         0.0        0.0   \n",
      "1       4.0       4.0  6584.0             0.0         0.0        0.0   \n",
      "2       4.0       4.0  7030.0             0.0         0.0        0.0   \n",
      "3       4.0       4.0  6550.0             0.0         0.0        0.0   \n",
      "4       4.0       4.0  6910.0             0.0         0.0        0.0   \n",
      "\n",
      "   orders_shops_closed  cumulative_orders  \n",
      "0                  0.0             6895.0  \n",
      "1                  0.0            13479.0  \n",
      "2                  0.0            20509.0  \n",
      "3                  0.0            27059.0  \n",
      "4                  0.0            33969.0  \n",
      "\n",
      "[5 rows x 85 columns]\n",
      "test_df_processed.head()       warehouse  holiday  shops_closed  winter_school_holidays  \\\n",
      "7340          4        0             0                       0   \n",
      "7341          4        0             0                       0   \n",
      "7342          4        0             0                       0   \n",
      "7343          4        0             0                       0   \n",
      "7344          4        0             0                       0   \n",
      "\n",
      "      school_holidays  year  month  day  day_of_week  week_of_year  ...  \\\n",
      "7340                0  2024      3   16            5            11  ...   \n",
      "7341                0  2024      3   17            6            11  ...   \n",
      "7342                0  2024      3   18            0            12  ...   \n",
      "7343                0  2024      3   19            1            12  ...   \n",
      "7344                0  2024      3   20            2            12  ...   \n",
      "\n",
      "      quarter1  quarter2  quarter3  quarter4  quarter5  orders_holiday  \\\n",
      "7340       1.0       1.0       1.0       1.0       1.0             0.0   \n",
      "7341       1.0       1.0       1.0       1.0       1.0             0.0   \n",
      "7342       1.0       1.0       1.0       1.0       1.0             0.0   \n",
      "7343       1.0       1.0       1.0       1.0       1.0             0.0   \n",
      "7344       1.0       1.0       1.0       1.0       1.0             0.0   \n",
      "\n",
      "      orders_wsh  orders_sh  orders_shops_closed  cumulative_orders  \n",
      "7340         0.0        0.0                  0.0          9218982.0  \n",
      "7341         0.0        0.0                  0.0          9228864.0  \n",
      "7342         0.0        0.0                  0.0          9238810.0  \n",
      "7343         0.0        0.0                  0.0          9249450.0  \n",
      "7344         0.0        0.0                  0.0          9261769.0  \n",
      "\n",
      "[5 rows x 84 columns]\n"
     ]
    }
   ],
   "execution_count": 180
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T05:11:40.758514Z",
     "start_time": "2024-08-23T05:11:40.744992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set random seed\n",
    "random_seed = 777\n",
    "# Split train data into features and target\n",
    "X = train_df_processed.drop(columns=['orders'])\n",
    "y = train_df_processed['orders']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1, random_state=random_seed)"
   ],
   "outputs": [],
   "execution_count": 181
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T04:21:20.804325Z",
     "start_time": "2024-08-23T02:41:58.252575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define search spaces for Bayesian Optimization\n",
    "search_spaces = {\n",
    "    'lgb': {\n",
    "        'n_estimators': Integer(100, 1000),\n",
    "        'num_leaves': Integer(20, 100),\n",
    "        'learning_rate': Real(0.001, 0.1, prior='log-uniform'),\n",
    "        'colsample_bytree': Real(0.4, 1.0),\n",
    "        'subsample': Real(0.5, 1.0),\n",
    "        'min_child_weight': Integer(1, 10),\n",
    "        'lambda_l1': Real(0, 1),\n",
    "        'lambda_l2': Real(0, 1)\n",
    "    },\n",
    "    'xgb': {\n",
    "        'n_estimators': Integer(100, 1000),\n",
    "        'max_depth': Integer(3, 15),\n",
    "        'learning_rate': Real(0.001, 0.1, prior='log-uniform'),\n",
    "        'colsample_bytree': Real(0.4, 1.0),\n",
    "        'subsample': Real(0.5, 1.0),\n",
    "        'min_child_weight': Integer(1, 10),\n",
    "        'gamma': Real(0, 5),\n",
    "        'lambda': Real(0, 1),\n",
    "        'alpha': Real(0, 1)\n",
    "    },\n",
    "    'cat': {\n",
    "        'iterations': Integer(100, 1000),\n",
    "        'depth': Integer(4, 12),\n",
    "        'learning_rate': Real(0.001, 0.1, prior='log-uniform'),\n",
    "        'l2_leaf_reg': Real(1, 10),\n",
    "        'border_count': Integer(32, 255),\n",
    "        'bagging_temperature': Real(0.0, 1.0),\n",
    "        'random_strength': Real(0.0, 1.0)\n",
    "    },\n",
    "    'rf': {\n",
    "        'n_estimators': Integer(100, 1000),\n",
    "        'max_depth': Integer(5, 50),\n",
    "        'min_samples_split': Integer(2, 20),\n",
    "        'min_samples_leaf': Integer(1, 10),\n",
    "        'max_features': Real(0.1, 1.0)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize the models with default parameters and GPU/multicore settings\n",
    "models = {\n",
    "    'lgb': LGBMRegressor(device='gpu',random_state=random_seed),\n",
    "    'xgb': XGBRegressor(tree_method='gpu_hist', random_state=random_seed),\n",
    "    'cat': CatBoostRegressor(task_type='GPU', random_state=random_seed, verbose=0),\n",
    "    'rf': RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=random_seed)\n",
    "}\n",
    "\n",
    "\n",
    "# models which won't be tuned\n",
    "lr_model = LogisticRegression(random_state=random_seed)\n",
    "ad_model = AdaBoostRegressor(random_state=random_seed)\n",
    "dt_model = DecisionTreeRegressor(random_state=random_seed)\n",
    "gb_model = GradientBoostingRegressor(random_state=random_seed)\n",
    "\n",
    "\n",
    "lr_model.fit(X_train, y_train)\n",
    "ad_model.fit(X_train, y_train)\n",
    "dt_model.fit(X_train, y_train)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Bayesian Optimization for each model\n",
    "opt_models = {}\n",
    "for model_name, model in models.items():\n",
    "    opt = BayesSearchCV(estimator=model, search_spaces=search_spaces.get(model_name, {}), n_iter=30, cv=5, random_state=random_seed,verbose=1,scoring=mape_scorer)\n",
    "    opt.fit(X_train, y_train)\n",
    "    opt_models[model_name] = opt.best_estimator_\n",
    "    print(model_name, opt.best_score_, opt.best_params_)\n",
    "\n",
    "# untuned model; doing this for time saving\n",
    "opt_models['lr'] =lr_model\n",
    "opt_models['ad'] =ad_model\n",
    "opt_models['dt'] =dt_model\n",
    "opt_models['gb'] =gb_model\n",
    "\n",
    "# Train optimized models on full training data\n",
    "stacking_train = np.zeros((X_train.shape[0], len(opt_models)))\n",
    "\n",
    "for i, (model_name, model) in enumerate(opt_models.items()):\n",
    "    stacking_train[:, i] = model.predict(X_train)\n",
    "\n",
    "\n",
    "# Define search spaces for the meta-models\n",
    "meta_search_spaces = {\n",
    "    'meta_model_1': {  # LGBMRegressor\n",
    "        'n_estimators': Integer(100, 1000),\n",
    "        'num_leaves': Integer(20, 100),\n",
    "        'learning_rate': Real(0.001, 0.1, prior='log-uniform'),\n",
    "        'colsample_bytree': Real(0.4, 1.0),\n",
    "    },\n",
    "    'meta_model_2': {  # CatBoostRegressor\n",
    "        'iterations': Integer(100, 1000),\n",
    "        'depth': Integer(4, 12),\n",
    "        'learning_rate': Real(0.001, 0.1, prior='log-uniform')\n",
    "    },\n",
    "    'meta_model_3': {  # XGBRegressor\n",
    "        'n_estimators': Integer(100, 1000),\n",
    "        'max_depth': Integer(3, 15),\n",
    "        'learning_rate': Real(0.001, 0.1, prior='log-uniform'),\n",
    "        'colsample_bytree': Real(0.4, 1.0),\n",
    "        'subsample': Real(0.5, 1.0)\n",
    "    },\n",
    "    'meta_model_4': {  # RandomForestRegressor\n",
    "        'n_estimators': Integer(100, 1000),\n",
    "        'max_depth': Integer(5, 50),\n",
    "        'min_samples_split': Integer(2, 20),\n",
    "        'min_samples_leaf': Integer(1, 10),\n",
    "        'max_features': Real(0.1, 1.0)\n",
    "    },\n",
    "    'meta_model_5': {  # GradientBoostingRegressor\n",
    "        'n_estimators': Integer(100, 1000),\n",
    "        'max_depth': Integer(3, 15),\n",
    "        'learning_rate': Real(0.001, 0.1, prior='log-uniform'),\n",
    "        'subsample': Real(0.5, 1.0),\n",
    "        'min_samples_split': Integer(2, 20),\n",
    "        'min_samples_leaf': Integer(1, 10),\n",
    "        'max_features': Real(0.1, 1.0)\n",
    "    },\n",
    "    'meta_model_6': {  # DecisionTreeRegressor\n",
    "        'max_depth': Integer(3, 15),\n",
    "        'min_samples_split': Integer(2, 20),\n",
    "        'min_samples_leaf': Integer(1, 10),\n",
    "        'max_features': Categorical([ 'sqrt', 'log2']),\n",
    "        'ccp_alpha': Real(0.0, 0.1)  # Cost-complexity pruning parameter\n",
    "    },\n",
    "    'meta_model_7': {  # AdaBoostRegressor\n",
    "        'n_estimators': Integer(50, 500),\n",
    "        'learning_rate': Real(0.001, 1.0, prior='log-uniform'),\n",
    "        'loss': Categorical(['linear', 'square', 'exponential'])\n",
    "    },\n",
    "    'meta_model_8': {  # LinearRegression\n",
    "        'fit_intercept': Categorical([True, False])\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize and optimize meta-models using Bayesian Optimization\n",
    "meta_models = {\n",
    "    'meta_model_1': LGBMRegressor(device='gpu', random_state=random_seed),\n",
    "    'meta_model_2': CatBoostRegressor(task_type='GPU', random_state=random_seed, verbose=0),\n",
    "    'meta_model_3': XGBRegressor(tree_method='gpu_hist', random_state=random_seed),\n",
    "    'meta_model_4': RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=random_seed),\n",
    "    'meta_model_5': GradientBoostingRegressor(random_state=random_seed),\n",
    "    'meta_model_6': DecisionTreeRegressor(random_state=random_seed),\n",
    "    'meta_model_7': AdaBoostRegressor(random_state=random_seed),\n",
    "    'meta_model_8': LinearRegression(n_jobs=-1)\n",
    "}\n",
    "\n",
    "opt_meta_models = {}\n",
    "for model_name, model in meta_models.items():\n",
    "    opt_meta = BayesSearchCV(estimator=model, search_spaces=meta_search_spaces.get(model_name, {}), n_iter=10, cv=5, random_state=random_seed, verbose=1, scoring=mape_scorer)\n",
    "    opt_meta.fit(stacking_train, y_train)\n",
    "    opt_meta_models[model_name] = opt_meta.best_estimator_\n",
    "    print(model_name, opt_meta.best_score_, opt_meta.best_params_)\n",
    "\n",
    "# drop the order column \n",
    "test_df_le=test_df.copy()\n",
    "\n",
    "level_2_train = np.zeros((X_train.shape[0], len(opt_meta_models)))\n",
    "for i, (model_name, model) in enumerate(opt_meta_models.items()):\n",
    "    print(model_name)\n",
    "    level_2_train[:, i] = model.predict(stacking_train)\n",
    "\n",
    "# the model first pass through original layer\n",
    "stacking_t=np.zeros((test_df_le.shape[0], len(opt_models)))\n",
    "for i, (model_name, model) in enumerate(opt_models.items()):\n",
    "    stacking_t[:, i] = model.predict(test_df_le)\n",
    "# pass the second layer. Which is meta-layer\n",
    "meta_stack=np.zeros((test_df_le.shape[0], len(opt_meta_models)))\n",
    "for i, (model_name, model) in enumerate(opt_meta_models.items()):\n",
    "    meta_stack[:, i] = model.predict(stacking_t)\n",
    "\n",
    "\n",
    "initial_weights = np.ones(len(meta_models)) / len(meta_models)\n",
    "\n",
    "# Final prediction\n",
    "submit_pred = np.dot(meta_stack, initial_weights)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.005766 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003637 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004236 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003791 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.006872 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.49667320189281094, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.49667320189281094\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8874678227816164, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8874678227816164\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003896 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003303 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003581 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003906 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004970 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004035 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003213 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003888 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003562 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004033 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4552037111581827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4552037111581827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.035966390387329746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.035966390387329746\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003638 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004229 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003521 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003726 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004064 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8739808005414181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8739808005414181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12091401349698919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12091401349698919\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003856 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004164 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003829 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003749 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.006145 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3980511773587153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3980511773587153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.47627445974899296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47627445974899296\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.006730 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003545 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003380 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004816 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003524 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35248652536652864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35248652536652864\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49450411433567165, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49450411433567165\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004052 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.007975 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004733 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.012463 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004214 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9123433317611236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9123433317611236\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1347397626764361, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1347397626764361\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003887 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003725 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003664 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004081 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003858 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7177573409958267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7177573409958267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5845870996285026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5845870996285026\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004283 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003367 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004991 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004256 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003894 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17602394071368724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17602394071368724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16281542628700144, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16281542628700144\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004435 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003836 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003355 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003446 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003480 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.570362932502081, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.570362932502081\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6348069729876964, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6348069729876964\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5542642693122322, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5542642693122322\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5542642693122322, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5542642693122322\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004646 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5542642693122322, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5542642693122322\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5542642693122322, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5542642693122322\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5542642693122322, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5542642693122322\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004133 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5542642693122322, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5542642693122322\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5542642693122322, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5542642693122322\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5542642693122322, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5542642693122322\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003553 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5542642693122322, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5542642693122322\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5542642693122322, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5542642693122322\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5542642693122322, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5542642693122322\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004089 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5542642693122322, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5542642693122322\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5542642693122322, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5542642693122322\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5542642693122322, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5542642693122322\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003619 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5542642693122322, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5542642693122322\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9791540389403565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9791540389403565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4392031119842665, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4392031119842665\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9791540389403565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9791540389403565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4392031119842665, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4392031119842665\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.005498 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9791540389403565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9791540389403565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4392031119842665, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4392031119842665\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9791540389403565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9791540389403565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4392031119842665, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4392031119842665\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9791540389403565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9791540389403565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4392031119842665, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4392031119842665\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.002959 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9791540389403565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9791540389403565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4392031119842665, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4392031119842665\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9791540389403565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9791540389403565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4392031119842665, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4392031119842665\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9791540389403565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9791540389403565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4392031119842665, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4392031119842665\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003829 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9791540389403565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9791540389403565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4392031119842665, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4392031119842665\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9791540389403565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9791540389403565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4392031119842665, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4392031119842665\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9791540389403565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9791540389403565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4392031119842665, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4392031119842665\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.006999 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9791540389403565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9791540389403565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4392031119842665, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4392031119842665\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9791540389403565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9791540389403565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4392031119842665, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4392031119842665\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9791540389403565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9791540389403565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4392031119842665, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4392031119842665\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003763 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9791540389403565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9791540389403565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4392031119842665, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4392031119842665\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.031155 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003695 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.005354 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003684 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003462 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4225522750743998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4225522750743998\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2757217321513345, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2757217321513345\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4225522750743998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4225522750743998\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2757217321513345, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2757217321513345\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004188 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4225522750743998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4225522750743998\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2757217321513345, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2757217321513345\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4225522750743998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4225522750743998\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2757217321513345, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2757217321513345\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4225522750743998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4225522750743998\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2757217321513345, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2757217321513345\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004015 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4225522750743998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4225522750743998\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2757217321513345, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2757217321513345\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4225522750743998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4225522750743998\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2757217321513345, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2757217321513345\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4225522750743998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4225522750743998\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2757217321513345, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2757217321513345\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003929 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4225522750743998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4225522750743998\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2757217321513345, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2757217321513345\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4225522750743998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4225522750743998\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2757217321513345, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2757217321513345\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4225522750743998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4225522750743998\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2757217321513345, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2757217321513345\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004445 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4225522750743998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4225522750743998\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2757217321513345, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2757217321513345\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4225522750743998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4225522750743998\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2757217321513345, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2757217321513345\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4225522750743998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4225522750743998\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2757217321513345, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2757217321513345\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.007785 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4225522750743998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4225522750743998\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2757217321513345, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2757217321513345\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004698 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004027 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004296 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003962 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004268 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004941 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004468 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.009566 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004113 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.005305 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4093505416593206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4093505416593206\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4093505416593206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4093505416593206\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004209 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4093505416593206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4093505416593206\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4093505416593206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4093505416593206\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4093505416593206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4093505416593206\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.010057 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4093505416593206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4093505416593206\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4093505416593206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4093505416593206\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4093505416593206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4093505416593206\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003920 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4093505416593206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4093505416593206\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4093505416593206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4093505416593206\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4093505416593206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4093505416593206\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.009928 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4093505416593206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4093505416593206\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4093505416593206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4093505416593206\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4093505416593206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4093505416593206\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004351 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4093505416593206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4093505416593206\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004171 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.007834 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004015 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004145 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003946 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.005299 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004062 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003996 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004567 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003449 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004323 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.009820 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004692 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004070 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.006148 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.031143508744234723, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.031143508744234723\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.031143508744234723, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.031143508744234723\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.006675 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.031143508744234723, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.031143508744234723\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.031143508744234723, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.031143508744234723\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.031143508744234723, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.031143508744234723\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003691 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.031143508744234723, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.031143508744234723\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.031143508744234723, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.031143508744234723\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.031143508744234723, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.031143508744234723\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004746 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.031143508744234723, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.031143508744234723\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.031143508744234723, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.031143508744234723\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.031143508744234723, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.031143508744234723\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003410 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.031143508744234723, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.031143508744234723\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.031143508744234723, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.031143508744234723\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.031143508744234723, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.031143508744234723\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004187 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.031143508744234723, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.031143508744234723\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9593588136965661, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9593588136965661\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9593588136965661, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9593588136965661\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004106 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9593588136965661, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9593588136965661\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9593588136965661, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9593588136965661\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9593588136965661, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9593588136965661\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003935 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9593588136965661, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9593588136965661\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9593588136965661, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9593588136965661\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9593588136965661, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9593588136965661\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.010204 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9593588136965661, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9593588136965661\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9593588136965661, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9593588136965661\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9593588136965661, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9593588136965661\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003693 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9593588136965661, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9593588136965661\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9593588136965661, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9593588136965661\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9593588136965661, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9593588136965661\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004081 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9593588136965661, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9593588136965661\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894887037842513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894887037842513\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894887037842513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894887037842513\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.005127 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894887037842513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894887037842513\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894887037842513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894887037842513\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894887037842513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894887037842513\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004006 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894887037842513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894887037842513\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894887037842513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894887037842513\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894887037842513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894887037842513\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004227 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894887037842513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894887037842513\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894887037842513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894887037842513\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894887037842513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894887037842513\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004266 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894887037842513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894887037842513\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894887037842513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894887037842513\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894887037842513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894887037842513\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004602 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894887037842513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894887037842513\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7723133759625459, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7723133759625459\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7723133759625459, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7723133759625459\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.005229 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7723133759625459, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7723133759625459\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7723133759625459, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7723133759625459\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7723133759625459, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7723133759625459\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003998 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7723133759625459, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7723133759625459\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7723133759625459, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7723133759625459\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7723133759625459, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7723133759625459\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003807 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7723133759625459, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7723133759625459\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7723133759625459, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7723133759625459\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7723133759625459, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7723133759625459\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003799 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7723133759625459, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7723133759625459\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7723133759625459, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7723133759625459\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7723133759625459, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7723133759625459\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.008717 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7723133759625459, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7723133759625459\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5004040079520194, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5004040079520194\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4722166358389546, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4722166358389546\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5004040079520194, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5004040079520194\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4722166358389546, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4722166358389546\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.007368 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5004040079520194, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5004040079520194\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4722166358389546, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4722166358389546\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5004040079520194, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5004040079520194\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4722166358389546, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4722166358389546\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5004040079520194, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5004040079520194\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4722166358389546, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4722166358389546\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004332 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5004040079520194, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5004040079520194\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4722166358389546, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4722166358389546\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5004040079520194, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5004040079520194\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4722166358389546, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4722166358389546\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5004040079520194, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5004040079520194\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4722166358389546, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4722166358389546\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003524 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5004040079520194, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5004040079520194\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4722166358389546, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4722166358389546\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5004040079520194, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5004040079520194\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4722166358389546, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4722166358389546\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5004040079520194, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5004040079520194\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4722166358389546, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4722166358389546\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003795 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5004040079520194, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5004040079520194\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4722166358389546, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4722166358389546\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5004040079520194, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5004040079520194\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4722166358389546, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4722166358389546\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5004040079520194, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5004040079520194\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4722166358389546, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4722166358389546\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003764 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5004040079520194, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5004040079520194\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4722166358389546, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4722166358389546\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6912874348290408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6912874348290408\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6912874348290408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6912874348290408\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004176 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6912874348290408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6912874348290408\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6912874348290408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6912874348290408\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6912874348290408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6912874348290408\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004465 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6912874348290408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6912874348290408\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6912874348290408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6912874348290408\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6912874348290408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6912874348290408\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003842 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6912874348290408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6912874348290408\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6912874348290408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6912874348290408\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6912874348290408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6912874348290408\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004247 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6912874348290408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6912874348290408\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6912874348290408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6912874348290408\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6912874348290408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6912874348290408\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003760 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6912874348290408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6912874348290408\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004293 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004007 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003566 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004367 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003667 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004131 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004373 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004204 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004070 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004160 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5030595302154366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5030595302154366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5030595302154366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5030595302154366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004303 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5030595302154366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5030595302154366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5030595302154366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5030595302154366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5030595302154366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5030595302154366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003841 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5030595302154366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5030595302154366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5030595302154366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5030595302154366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5030595302154366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5030595302154366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003386 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5030595302154366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5030595302154366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5030595302154366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5030595302154366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5030595302154366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5030595302154366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004316 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5030595302154366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5030595302154366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5030595302154366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5030595302154366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5030595302154366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5030595302154366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004325 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5030595302154366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5030595302154366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004485 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004109 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.003840 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.004131 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 61\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.25 MB) transferred to GPU in 0.008504 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1145\n",
      "[LightGBM] [Info] Number of data points in the train set: 7339, number of used features: 62\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 44 dense feature groups (0.31 MB) transferred to GPU in 0.004595 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5535.446110\n",
      "lgb -0.032523270492050824 OrderedDict({'colsample_bytree': 1.0, 'lambda_l1': 1.0, 'lambda_l2': 0.808200821287029, 'learning_rate': 0.025307519405429236, 'min_child_weight': 7, 'n_estimators': 1000, 'num_leaves': 100, 'subsample': 0.9966316922621006})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "xgb -0.03278345951172427 OrderedDict({'alpha': 0.6945367674283031, 'colsample_bytree': 1.0, 'gamma': 5.0, 'lambda': 0.05608623437958411, 'learning_rate': 0.014971041774732024, 'max_depth': 15, 'min_child_weight': 9, 'n_estimators': 766, 'subsample': 0.6222949383072757})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "cat -0.03405830534456074 OrderedDict({'bagging_temperature': 0.0, 'border_count': 32, 'depth': 12, 'iterations': 314, 'l2_leaf_reg': 1.0, 'learning_rate': 0.1, 'random_strength': 0.0})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "rf -0.03821125884532879 OrderedDict({'max_depth': 33, 'max_features': 0.855057704560261, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000})\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1681\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000510 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000456 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1677\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000470 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000469 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1675\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000548 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1681\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000487 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000478 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1677\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000478 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000732 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1675\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000651 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1681\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000454 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000425 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1677\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000455 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000442 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1675\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000593 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1681\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000504 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000455 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1677\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000452 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000497 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1675\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000483 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1681\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000451 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000536 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1677\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000420 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000605 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1675\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000554 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1681\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000456 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000531 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1677\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000405 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000433 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1675\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000464 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1681\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000472 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000439 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1677\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000478 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000462 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1675\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000554 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1681\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000484 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000797 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1677\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000507 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.011210 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1675\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000456 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1681\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000585 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000453 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1677\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000528 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000460 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1675\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000482 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1681\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000540 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5542.428717\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000552 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5538.427355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1677\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000434 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.732243\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5871, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000520 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5536.773633\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1675\n",
      "[LightGBM] [Info] Number of data points in the train set: 5872, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.04 MB) transferred to GPU in 0.000544 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5518.871424\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1686\n",
      "[LightGBM] [Info] Number of data points in the train set: 7339, number of used features: 8\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 7 dense feature groups (0.06 MB) transferred to GPU in 0.000494 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5535.446110\n",
      "meta_model_1 -0.0030806164847700843 OrderedDict({'colsample_bytree': 0.8037902863531624, 'learning_rate': 0.06678618920982962, 'n_estimators': 221, 'num_leaves': 69})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "meta_model_2 -0.010651975590006666 OrderedDict({'depth': 6, 'iterations': 547, 'learning_rate': 0.0595573883918703})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "meta_model_3 -0.0030301438539807033 OrderedDict({'colsample_bytree': 0.9090704690562509, 'learning_rate': 0.010583889705671753, 'max_depth': 5, 'n_estimators': 862, 'subsample': 0.8774801253694525})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "meta_model_4 -0.0008315378288732446 OrderedDict({'max_depth': 33, 'max_features': 0.8865827204872763, 'min_samples_leaf': 2, 'min_samples_split': 12, 'n_estimators': 533})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "meta_model_5 -0.0012919668923515493 OrderedDict({'learning_rate': 0.02138940088929268, 'max_depth': 10, 'max_features': 0.6713262756889268, 'min_samples_leaf': 4, 'min_samples_split': 14, 'n_estimators': 749, 'subsample': 0.6094913668371814})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "meta_model_6 -0.0071577260631709135 OrderedDict({'ccp_alpha': 0.06650993101418151, 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 14})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "meta_model_7 -0.026872766834319467 OrderedDict({'learning_rate': 0.3510365561653655, 'loss': 'square', 'n_estimators': 130})\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "meta_model_8 -3.193380475468901e-16 OrderedDict({'fit_intercept': True})\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['orders'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[170], line 158\u001B[0m\n\u001B[0;32m    155\u001B[0m     \u001B[38;5;28mprint\u001B[39m(model_name, opt_meta\u001B[38;5;241m.\u001B[39mbest_score_, opt_meta\u001B[38;5;241m.\u001B[39mbest_params_)\n\u001B[0;32m    157\u001B[0m \u001B[38;5;66;03m# drop the order column \u001B[39;00m\n\u001B[1;32m--> 158\u001B[0m test_df_le\u001B[38;5;241m=\u001B[39m\u001B[43mtest_df_le\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43morders\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    160\u001B[0m level_2_train \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((X_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mlen\u001B[39m(opt_meta_models)))\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (model_name, model) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(opt_meta_models\u001B[38;5;241m.\u001B[39mitems()):\n",
      "File \u001B[1;32m~\\DataspellProjects\\Forecast\\project1\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001B[0m, in \u001B[0;36mDataFrame.drop\u001B[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[0;32m   5433\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdrop\u001B[39m(\n\u001B[0;32m   5434\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   5435\u001B[0m     labels: IndexLabel \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   5442\u001B[0m     errors: IgnoreRaise \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   5443\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   5444\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   5445\u001B[0m \u001B[38;5;124;03m    Drop specified labels from rows or columns.\u001B[39;00m\n\u001B[0;32m   5446\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   5579\u001B[0m \u001B[38;5;124;03m            weight  1.0     0.8\u001B[39;00m\n\u001B[0;32m   5580\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 5581\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   5582\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5583\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5584\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5585\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5586\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5587\u001B[0m \u001B[43m        \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5588\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5589\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\DataspellProjects\\Forecast\\project1\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001B[0m, in \u001B[0;36mNDFrame.drop\u001B[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[0;32m   4786\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m axis, labels \u001B[38;5;129;01min\u001B[39;00m axes\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m   4787\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 4788\u001B[0m         obj \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_drop_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4790\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n\u001B[0;32m   4791\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_inplace(obj)\n",
      "File \u001B[1;32m~\\DataspellProjects\\Forecast\\project1\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001B[0m, in \u001B[0;36mNDFrame._drop_axis\u001B[1;34m(self, labels, axis, level, errors, only_slice)\u001B[0m\n\u001B[0;32m   4828\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mdrop(labels, level\u001B[38;5;241m=\u001B[39mlevel, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[0;32m   4829\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 4830\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m \u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4831\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mget_indexer(new_axis)\n\u001B[0;32m   4833\u001B[0m \u001B[38;5;66;03m# Case for non-unique axis\u001B[39;00m\n\u001B[0;32m   4834\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\DataspellProjects\\Forecast\\project1\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001B[0m, in \u001B[0;36mIndex.drop\u001B[1;34m(self, labels, errors)\u001B[0m\n\u001B[0;32m   7068\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[0;32m   7069\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m-> 7070\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabels[mask]\u001B[38;5;241m.\u001B[39mtolist()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found in axis\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   7071\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m indexer[\u001B[38;5;241m~\u001B[39mmask]\n\u001B[0;32m   7072\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelete(indexer)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"['orders'] not found in axis\""
     ]
    }
   ],
   "execution_count": 170
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T04:39:59.301741Z",
     "start_time": "2024-08-23T04:39:58.514199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# drop the order column \n",
    "test_df_le=test_df_processed\n",
    "\n",
    "level_2_train = np.zeros((X_train.shape[0], len(opt_meta_models)))\n",
    "for i, (model_name, model) in enumerate(opt_meta_models.items()):\n",
    "    print(model_name)\n",
    "    level_2_train[:, i] = model.predict(stacking_train)\n",
    "\n",
    "# the model first pass through original layer\n",
    "stacking_t=np.zeros((test_df_le.shape[0], len(opt_models)))\n",
    "for i, (model_name, model) in enumerate(opt_models.items()):\n",
    "    stacking_t[:, i] = model.predict(test_df_le)\n",
    "# pass the second layer. Which is meta-layer\n",
    "meta_stack=np.zeros((test_df_le.shape[0], len(opt_meta_models)))\n",
    "for i, (model_name, model) in enumerate(opt_meta_models.items()):\n",
    "    meta_stack[:, i] = model.predict(stacking_t)\n",
    "\n",
    "\n",
    "initial_weights = np.ones(len(meta_models)) / len(meta_models)\n",
    "\n",
    "# Final prediction\n",
    "submit_pred = np.dot(meta_stack, initial_weights)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_model_1\n",
      "meta_model_2\n",
      "meta_model_3\n",
      "meta_model_4\n",
      "meta_model_5\n",
      "meta_model_6\n",
      "meta_model_7\n",
      "meta_model_8\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.808200821287029, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.808200821287029\n"
     ]
    }
   ],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T04:40:02.933729Z",
     "start_time": "2024-08-23T04:40:02.927077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a DataFrame for submission with 'id' and 'Target'\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_id,         # Test IDs for each prediction\n",
    "    'Target': submit_pred  # Final predictions for submission\n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission.to_csv('submission_ultimate2.csv', index=False)  # Save without including row indices\n",
    "\n",
    "# Print the submission DataFrame to verify the results\n",
    "print(submission)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        id        Target\n",
      "0      Prague_1_2024-03-16  10906.720675\n",
      "1      Prague_1_2024-03-17  10543.092249\n",
      "2      Prague_1_2024-03-18   9599.860299\n",
      "3      Prague_1_2024-03-19   9291.414551\n",
      "4      Prague_1_2024-03-20   9315.107073\n",
      "..                     ...           ...\n",
      "392  Budapest_1_2024-05-11   7073.880302\n",
      "393  Budapest_1_2024-05-12   6720.785400\n",
      "394  Budapest_1_2024-05-13   6704.118498\n",
      "395  Budapest_1_2024-05-14   6716.275756\n",
      "396  Budapest_1_2024-05-15   7926.960434\n",
      "\n",
      "[397 rows x 2 columns]\n"
     ]
    }
   ],
   "execution_count": 173
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ">### New attempt"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T06:07:58.902509Z",
     "start_time": "2024-08-23T05:46:04.673990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cross-validation Setup\n",
    "# Define the number of splits for k-fold cross-validation\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "\n",
    "# Initialize arrays to store predictions from base models for stacking\n",
    "stacking_train = np.zeros((X_train.shape[0], 8))\n",
    "stacking_test = np.zeros((X_test.shape[0], 8))\n",
    "\n",
    "# Initialize base models for stacking\n",
    "lgb_model = LGBMRegressor(\n",
    "colsample_bytree=0.9090704690562509,\n",
    "lambda_l1=0.5123226527180421,\n",
    "lambda_l2=0.17762444404308067,\n",
    "learning_rate=0.04939196011309037,\n",
    "min_child_weight=8,\n",
    "n_estimators=501,\n",
    "num_leaves=53,\n",
    "subsample=0.5052004980567765,\n",
    "random_state=random_seed,\n",
    "device='gpu'  # Assuming GPU usage as in previous examples\n",
    ")\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "alpha=0.0,\n",
    "colsample_bytree=1.0,\n",
    "gamma=5.0,learning_rate=0.025678181688152554,max_depth=15,min_child_weight=10,n_estimators=686,subsample=0.5,random_state=random_seed,tree_method='gpu_hist') # Assuming GPU usage as in previous examples)\n",
    "\n",
    "\n",
    "cat_model = CatBoostRegressor(\n",
    "    bagging_temperature=1.0,\n",
    "    border_count=133,\n",
    "    depth=12,\n",
    "    iterations=1000,\n",
    "    l2_leaf_reg=10.0,\n",
    "    learning_rate=0.1,\n",
    "    random_strength=0.0,\n",
    "    random_state=random_seed,\n",
    "    task_type='GPU',  # Assuming GPU usage as in previous examples\n",
    "    verbose=0  # Suppress training output\n",
    ")\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    max_depth=31,\n",
    "    max_features=1.0,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=1000,\n",
    "    random_state=random_seed,\n",
    "    n_jobs=-1  # Utilize all available CPU cores\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lr_model = LogisticRegression(random_state=random_seed)\n",
    "ad_model = AdaBoostRegressor(random_state=random_seed)\n",
    "dt_model = DecisionTreeRegressor(random_state=random_seed)\n",
    "gb_model = GradientBoostingRegressor(random_state=random_seed)\n",
    "\n",
    "# Train base models with cross-validation and generate stacking features\n",
    "for train_idx, val_idx in kf.split(X_train):\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    # Fit each base model on training data\n",
    "    lgb_model.fit(X_tr, y_tr)\n",
    "    xgb_model.fit(X_tr, y_tr)\n",
    "    cat_model.fit(X_tr, y_tr)\n",
    "    rf_model.fit(X_tr, y_tr)\n",
    "    lr_model.fit(X_tr, y_tr)\n",
    "    ad_model.fit(X_tr, y_tr)\n",
    "    dt_model.fit(X_tr, y_tr)\n",
    "    gb_model.fit(X_tr, y_tr)\n",
    "\n",
    "    # Predict on validation set for stacking features\n",
    "    stacking_train[val_idx, 0] = lgb_model.predict(X_val)\n",
    "    stacking_train[val_idx, 1] = xgb_model.predict(X_val)\n",
    "    stacking_train[val_idx, 2] = cat_model.predict(X_val)\n",
    "    stacking_train[val_idx, 3] = rf_model.predict(X_val)\n",
    "    stacking_train[val_idx, 4] = lr_model.predict(X_val)\n",
    "    stacking_train[val_idx, 5] = ad_model.predict(X_val)\n",
    "    stacking_train[val_idx, 6] = dt_model.predict(X_val)\n",
    "    stacking_train[val_idx, 7] = gb_model.predict(X_val)\n",
    "\n",
    "    # Predict on test set and average predictions over all folds\n",
    "    stacking_test[:, 0] += lgb_model.predict(X_test) / n_splits\n",
    "    stacking_test[:, 1] += xgb_model.predict(X_test) / n_splits\n",
    "    stacking_test[:, 2] += cat_model.predict(X_test) / n_splits\n",
    "    stacking_test[:, 3] += rf_model.predict(X_test) / n_splits\n",
    "    stacking_test[:, 4] += lr_model.predict(X_test) / n_splits\n",
    "    stacking_test[:, 5] += ad_model.predict(X_test) / n_splits\n",
    "    stacking_test[:, 6] += dt_model.predict(X_test) / n_splits\n",
    "    stacking_test[:, 7] += gb_model.predict(X_test) / n_splits"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 980\n",
      "[LightGBM] [Info] Number of data points in the train set: 6605, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.10 MB) transferred to GPU in 0.001349 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5540.911128\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 983\n",
      "[LightGBM] [Info] Number of data points in the train set: 6605, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.10 MB) transferred to GPU in 0.001599 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5534.855261\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 983\n",
      "[LightGBM] [Info] Number of data points in the train set: 6605, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.10 MB) transferred to GPU in 0.001553 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5533.542316\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 985\n",
      "[LightGBM] [Info] Number of data points in the train set: 6605, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.10 MB) transferred to GPU in 0.001555 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5534.330507\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 980\n",
      "[LightGBM] [Info] Number of data points in the train set: 6605, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.10 MB) transferred to GPU in 0.001533 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5528.689780\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 983\n",
      "[LightGBM] [Info] Number of data points in the train set: 6605, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.10 MB) transferred to GPU in 0.001386 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5544.863588\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 6605, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.10 MB) transferred to GPU in 0.001406 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5551.502044\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 983\n",
      "[LightGBM] [Info] Number of data points in the train set: 6605, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.10 MB) transferred to GPU in 0.001334 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5526.702195\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 980\n",
      "[LightGBM] [Info] Number of data points in the train set: 6605, number of used features: 26\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.10 MB) transferred to GPU in 0.001180 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5533.006964\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 986\n",
      "[LightGBM] [Info] Number of data points in the train set: 6606, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 14 dense feature groups (0.10 MB) transferred to GPU in 0.001296 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5526.058734\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n"
     ]
    }
   ],
   "execution_count": 208
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T06:08:06.404722Z",
     "start_time": "2024-08-23T06:07:58.902509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train meta-models\n",
    "meta_model_1 = LGBMRegressor(n_estimators=150, num_leaves=15, learning_rate=0.05, colsample_bytree=0.6, lambda_l1=0.2, lambda_l2=0.2, random_state=random_seed)\n",
    "meta_model_2 = CatBoostRegressor(verbose=0, random_state = random_seed)\n",
    "meta_model_3 = XGBRegressor(random_state = random_seed)\n",
    "meta_model_4 = RandomForestRegressor(n_estimators=100, random_state=random_seed)\n",
    "meta_model_5 = GradientBoostingRegressor(random_state=random_seed)\n",
    "meta_model_6 = DecisionTreeRegressor(random_state=random_seed)\n",
    "meta_model_7 = AdaBoostRegressor(random_state=random_seed)\n",
    "meta_model_8 = LinearRegression()\n",
    "\n",
    "meta_model_1.fit(stacking_train, y_train)\n",
    "meta_model_2.fit(stacking_train, y_train)\n",
    "meta_model_3.fit(stacking_train, y_train)\n",
    "meta_model_4.fit(stacking_train, y_train)\n",
    "meta_model_5.fit(stacking_train, y_train)\n",
    "meta_model_6.fit(stacking_train, y_train)\n",
    "meta_model_7.fit(stacking_train, y_train)\n",
    "meta_model_8.fit(stacking_train, y_train)\n",
    "\n",
    "best_iteration_1 = meta_model_1.best_iteration_\n",
    "best_iteration_2 = meta_model_2.best_iteration_\n",
    "\n",
    "# Predict on test set using meta-models\n",
    "meta_pred_1 = meta_model_1.predict(stacking_test)\n",
    "meta_pred_2 = meta_model_2.predict(stacking_test)\n",
    "meta_pred_3 = meta_model_3.predict(stacking_test)\n",
    "meta_pred_4 = meta_model_4.predict(stacking_test)\n",
    "meta_pred_5 = meta_model_5.predict(stacking_test)\n",
    "meta_pred_6 = meta_model_6.predict(stacking_test)\n",
    "meta_pred_7 = meta_model_7.predict(stacking_test)\n",
    "meta_pred_8 = meta_model_8.predict(stacking_test)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.2, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1909\n",
      "[LightGBM] [Info] Number of data points in the train set: 7339, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 5535.446110\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n"
     ]
    }
   ],
   "execution_count": 209
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T06:08:06.701079Z",
     "start_time": "2024-08-23T06:08:06.524111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prediction\n",
    "# Drop the 'orders' column from the test DataFrame as it is not needed for predictions\n",
    "# test_df_le = test_df_le.drop(columns=['date', 'orders'])  # Original line commented out\n",
    "test_df_le=test_df_le.drop(columns=[\"orders\"])# Drop 'orders' column\n",
    "\n",
    "# Generate predictions using each of the base models\n",
    "lgb_pred_test = lgb_model.predict(test_df_le)        # Predictions from LightGBM model\n",
    "xgb_pred_test = xgb_model.predict(test_df_le)        # Predictions from XGBoost model\n",
    "cat_pred_test = cat_model.predict(test_df_le)        # Predictions from CatBoost model\n",
    "rf_pred_test = rf_model.predict(test_df_le)          # Predictions from Random Forest model\n",
    "lr_pred_test = lr_model.predict(test_df_le)          # Predictions from Logistic Regression model\n",
    "ad_pred_test = ad_model.predict(test_df_le)          # Predictions from AdaBoost model\n",
    "dt_pred_test = dt_model.predict(test_df_le)          # Predictions from Decision Tree model\n",
    "gb_pred_test = gb_model.predict(test_df_le)          # Predictions from Gradient Boosting model\n",
    "\n",
    "# Stack predictions from the various models into a single array for stacking\n",
    "# stacking_test_df_le = np.vstack([lgb_pred_test, xgb_pred_test, cat_pred_test, rf_pred_test]).T  # Original line commented out\n",
    "stacking_test_df_le = np.vstack([lgb_pred_test, xgb_pred_test, cat_pred_test, rf_pred_test, lr_pred_test, ad_pred_test, dt_pred_test, gb_pred_test]).T\n",
    "\n",
    "\n",
    "# submit_pred = (\n",
    "#     meta_pred_1 * weights['meta_model_1'] +\n",
    "#     meta_pred_2 * weights['meta_model_2'] +\n",
    "#     meta_pred_3 * weights['meta_model_3'] +\n",
    "#     meta_pred_4 * weights['meta_model_4'] +\n",
    "#     meta_pred_5 * weights['meta_model_5'] +\n",
    "#     meta_pred_6 * weights['meta_model_6'] +\n",
    "#     meta_pred_7 * weights['meta_model_7'] +\n",
    "#     meta_pred_8 * weights['meta_model_8']\n",
    "# )\n",
    "\n",
    "# Generate predictions using the meta-models on the stacked test predictions\n",
    "submit_pred_1 = meta_model_1.predict(stacking_test_df_le)  # Predictions from the first meta-model\n",
    "submit_pred_2 = meta_model_2.predict(stacking_test_df_le)  # Predictions from the second meta-model\n",
    "submit_pred_3 = meta_model_3.predict(stacking_test_df_le)  # Predictions from the third meta-model\n",
    "submit_pred_4 = meta_model_4.predict(stacking_test_df_le)  # Predictions from the fourth meta-model\n",
    "submit_pred_5 = meta_model_5.predict(stacking_test_df_le)  # Predictions from the fifth meta-model\n",
    "submit_pred_6 = meta_model_6.predict(stacking_test_df_le)  # Predictions from the sixth meta-model\n",
    "submit_pred_7 = meta_model_7.predict(stacking_test_df_le)  # Predictions from the seventh meta-model\n",
    "submit_pred_8 = meta_model_8.predict(stacking_test_df_le)  # Predictions from the eight meta-model\n",
    "\n",
    "\n",
    "# # Define weights for each model's predictions in the final ensemble\n",
    "# weights = {\n",
    "#     'cat_test_preds': 0.10,  # Weight for CatBoost predictions\n",
    "#     'lgb_test_preds': 0.10,   # Weight for LightGBM predictions\n",
    "#     'xgb_test_preds': 0.40,   # Weight for XGBoost predictions\n",
    "#     'rf_test_preds': 0.10,     # Weight for Random Forest predictions\n",
    "#     'xtr_test_preds': 0.30,    # Weight for the final model's predictions\n",
    "# }\n",
    "\n",
    "weights = {\n",
    "    'meta_model_1': 0.125,\n",
    "    'meta_model_2': 0.125,\n",
    "    'meta_model_3': 0.125,\n",
    "    'meta_model_4': 0.125,\n",
    "    'meta_model_5': 0.125,\n",
    "    'meta_model_6': 0.125,\n",
    "    'meta_model_7': 0.125,\n",
    "    'meta_model_8': 0.125,\n",
    "}\n",
    "\n",
    "# Calculate the weighted predictions for each model\n",
    "meta_model_1_weighted = submit_pred_2 * weights['meta_model_1']  # Weighted predictions for CatBoost\n",
    "meta_model_2_weighted = submit_pred_1 * weights['meta_model_2']  # Weighted predictions for LightGBM\n",
    "meta_model_3_weighted = submit_pred_3 * weights['meta_model_3']  # Weighted predictions for XGBoost\n",
    "meta_model_4_weighted = submit_pred_4 * weights['meta_model_4']  # Weighted predictions for Random Forest\n",
    "meta_model_5_weighted = submit_pred_5 * weights['meta_model_5']\n",
    "meta_model_6_weighted = submit_pred_6 * weights['meta_model_6']\n",
    "meta_model_7_weighted = submit_pred_7 * weights['meta_model_7']\n",
    "meta_model_8_weighted = submit_pred_8 * weights['meta_model_8']\n",
    "\n",
    "# Combine all weighted predictions to obtain the final submission prediction\n",
    "submit_pred = meta_model_1_weighted + meta_model_2_weighted + meta_model_3_weighted + meta_model_4_weighted + meta_model_5_weighted + meta_model_6_weighted + meta_model_7_weighted + meta_model_8_weighted"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.5123226527180421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5123226527180421\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17762444404308067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17762444404308067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n"
     ]
    }
   ],
   "execution_count": 210
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T06:08:06.823719Z",
     "start_time": "2024-08-23T06:08:06.816956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a DataFrame for submission with 'id' and 'Target'\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_id,         # Test IDs for each prediction\n",
    "    'Target': submit_pred  # Final predictions for submission\n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission.to_csv('submission_ultimate5.csv', index=False)  # Save without including row indices\n",
    "\n",
    "# Print the submission DataFrame to verify the results\n",
    "print(submission)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        id        Target\n",
      "0      Prague_1_2024-03-16  10468.963923\n",
      "1      Prague_1_2024-03-17  10295.205614\n",
      "2      Prague_1_2024-03-18   9832.579028\n",
      "3      Prague_1_2024-03-19   9568.869854\n",
      "4      Prague_1_2024-03-20   9578.687128\n",
      "..                     ...           ...\n",
      "392  Budapest_1_2024-05-11   6816.031763\n",
      "393  Budapest_1_2024-05-12   6367.650992\n",
      "394  Budapest_1_2024-05-13   6451.108525\n",
      "395  Budapest_1_2024-05-14   6406.536346\n",
      "396  Budapest_1_2024-05-15   6380.408212\n",
      "\n",
      "[397 rows x 2 columns]\n"
     ]
    }
   ],
   "execution_count": 211
  }
 ]
}
